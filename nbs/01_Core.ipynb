{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core module\n",
    "\n",
    "> The core functions for making CHP markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from __future__ import print_function\n",
    "from SEQLinkage.Utils import *\n",
    "from SEQLinkage.Runner import *\n",
    "from SEQLinkage.Linkage import *\n",
    "from multiprocessing import Process, Queue\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import sys, faulthandler, platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from itertools import repeat\n",
    "if sys.version_info.major == 2:\n",
    "    from cstatgen import cstatgen_py2 as cstatgen\n",
    "    from cstatgen.egglib import Align\n",
    "else:\n",
    "    from cstatgen import cstatgen_py3 as cstatgen\n",
    "    import egglib\n",
    "    from egglib import Align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RData class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class RData(dict):\n",
    "    def __init__(self, vcf, tfam,anno_file=None,fam_pop_file=None,allele_freq_info = None,included_variant_file=None):\n",
    "        # tfam.samples: a dict of {sid:[fid, pid, mid, sex, trait], ...}\n",
    "        # tfam.families: a dict of {fid:[s1, s2 ...], ...}\n",
    "        self.tfam = TFAMParser(tfam)\n",
    "        # name of allele frequency meta info\n",
    "        self.af_info = allele_freq_info\n",
    "        self.vs = self.load_vcf(vcf)\n",
    "        self.fam_pop = self.load_fam_info(fam_pop_file)\n",
    "        self.anno = self.load_anno(anno_file,included_variant_file)\n",
    "        self.samples_vcf = self.vs.GetSampleNames()\n",
    "        self.samples_not_vcf = checkSamples(self.samples_vcf, self.tfam.samples.keys())[1]\n",
    "        self.fam,self.fam_vcf=self.load_fam(tfam)\n",
    "        # samples have to be in both vcf and tfam data\n",
    "        self.samples = OrderedDict([(k, self.tfam.samples[k]) for k in self.samples_vcf if k in self.tfam.samples])\n",
    "        # a dict of {fid:[member names], ...}\n",
    "        self.families = {k : [x for x in self.samples if x in self.tfam.families[k]] for k in self.tfam.families}\n",
    "        # a dict of {fid:[idx ...], ...}\n",
    "        self.famsampidx = {}\n",
    "        # a dict of {fid:[maf1, maf2 ...]}\n",
    "        self.maf = OrderedDict()\n",
    "        # finalized sub_regions that are compliant to all families\n",
    "        self.complied_markers = []\n",
    "        # finalized sub regions (variants)\n",
    "        self.combined_regions = []\n",
    "        self.coordinates_by_region = []\n",
    "        # RV varnames by family\n",
    "        self.varnames_by_fam = {}\n",
    "        self.patterns={}\n",
    "        self.gnomAD_estimate={'AFR':(1-0.4589)/(2*7652),'AMR':(1-0.4455)/(2*16791),'ASJ':(1-0.2357)/(2*4925),'EAS':(1-0.4735)/(2*8624),'FIN':(1-0.3048)/(2*11150),'NFE':(1-0.5729)/(2*55860),'OTH':(1-0.4386)/(2*2743),'SAS':(1-0.5624)/(2*15391)}\n",
    "        # reorder family samples based on order of VCF file\n",
    "        for k in list(self.families.keys()):\n",
    "            if len(self.families[k]) == 0:\n",
    "                # skip families having no samples in VCF file\n",
    "                del self.families[k]\n",
    "            else:\n",
    "                self.famsampidx[k] = [i for i, x in enumerate(self.samples_vcf) if x in self.families[k]]\n",
    "        # a dict of {fid:[idx ...], ...}\n",
    "        self.famvaridx = {}\n",
    "        self.famvarmafs = {}\n",
    "        \n",
    "        self.freq_by_fam = {}\n",
    "        self.include_vars = []\n",
    "        self.total_varnames={}\n",
    "        self.total_mafs={}\n",
    "        self.wt_maf={}\n",
    "        self.freq = []\n",
    "        self.genotype_all={}\n",
    "        self.mle_mafs={}\n",
    "        self.missing_persons=[]\n",
    "        self.reset()\n",
    "    \n",
    "    def load_vcf(self,vcf):\n",
    "        # load VCF file header\n",
    "        return cstatgen.VCFstream(vcf)\n",
    "    def load_anno(self,anno_file,included_variant_file=None):\n",
    "        if anno_file is None:\n",
    "            return None\n",
    "        anno = pd.read_csv(anno_file)\n",
    "        anno.index = list(anno.Otherinfo1)\n",
    "        anno = anno[~anno.index.duplicated()]\n",
    "        if included_variant_file:\n",
    "            included_variants= pd.read_csv(included_variant_file)\n",
    "            anno = anno.loc[included_variants,:]\n",
    "        tmp = anno[list(set(self.fam_pop.values()))]\n",
    "        tmp = tmp.replace('.',np.nan) \n",
    "        tmp = tmp.replace(0,np.nan)\n",
    "        anno = pd.concat([anno[['Chr','Start']],tmp.astype(np.float64)],axis=1)\n",
    "        anno = anno.dropna()\n",
    "        return anno\n",
    "    def load_fam_info(self,fam_pop_file):\n",
    "        if fam_pop_file is None:\n",
    "            return None\n",
    "        fam_pop = {}\n",
    "        with open(fam_pop_file) as f:\n",
    "            for line in f:\n",
    "                key, value = line.split()\n",
    "                if value == 'NA':   #Fixme: deal with missing info\n",
    "                    fam_pop[key]=self.af_info\n",
    "                else:\n",
    "                    fam_pop[key] = value\n",
    "        return fam_pop\n",
    "    def load_fam(self,fam_path):\n",
    "        fam = pd.read_csv(fam_path,delim_whitespace=True,header=None,names=['fid','iid','fathid','mothid','sex','trait'])\n",
    "        fam.index = list(fam.iid)\n",
    "        fam.fid=fam.fid.astype(str)\n",
    "        fam.loc[fam.trait==-9,'trait']=0\n",
    "        fam['vcf']=False\n",
    "        fam.loc[fam.index.isin(self.samples_vcf),'vcf']=True\n",
    "        fam_d,fam_vcf ={},{}\n",
    "        for i in fam.fid.unique():\n",
    "            x=fam[fam.fid==i]\n",
    "            fam_d[i]=x.iloc[:,:6]\n",
    "            fam_vcf[i]=x['vcf']\n",
    "        return fam_d,fam_vcf\n",
    "        \n",
    "    \n",
    "    def get_regions(self,step=1000):\n",
    "        '''separate chromosome to regions'''\n",
    "        regions=[]\n",
    "        chrom=self.anno.Chr.unique()[0] \n",
    "        for i,s in enumerate(self.anno.Start):\n",
    "            if i==0:\n",
    "                pre=None\n",
    "                cur=s\n",
    "            elif i%step==0:\n",
    "                pre=cur\n",
    "                cur=s\n",
    "                regions.append([str(chrom),str(pre),str(cur),'R'+str(pre)+'_'+str(cur),'.', '.', '.'])\n",
    "        if cur!=s:\n",
    "            pre=cur\n",
    "            cur=s\n",
    "            regions.append([str(chrom),str(pre),str(cur),'R'+str(pre)+'_'+str(cur),'.', '.', '.'])\n",
    "        return regions\n",
    "\n",
    "    def reset(self):\n",
    "        for item in self.tfam.samples: #for all samples in fam ( with or without vcfs)\n",
    "            self[item] = []\n",
    "            self.genotype_all[item] = []\n",
    "        self.variants = []\n",
    "        self.include_vars = []\n",
    "        self.total_varnames={}\n",
    "        self.total_mafs={}\n",
    "        self.chrom = None\n",
    "        for k in self.families.keys():\n",
    "            self.famvaridx[k] = []\n",
    "            self.famvarmafs[k] = []\n",
    "        self.maf = OrderedDict()\n",
    "        # superMarkerCount is the max num. of recombinant fragments among all fams\n",
    "        self.superMarkerCount = 0\n",
    "        self.complied_markers = []\n",
    "        self.combined_regions = []\n",
    "        self.coordinates_by_region = []\n",
    "        self.patterns={}\n",
    "        self.missing_persons=[]\n",
    "        self.gss = {} #test line\n",
    "\n",
    "\n",
    "    def getMidPosition(self):\n",
    "        if len(self.variants) == 0:\n",
    "            return None\n",
    "        return sum([x[1] for x in self.variants]) / len(self.variants)\n",
    "\n",
    "    def getFamVariants(self, fam, style = None):\n",
    "        if style is None:\n",
    "            return [item for idx, item in enumerate(self.variants) if idx in self.famvaridx[fam]]\n",
    "        elif style == \"map\":\n",
    "            names = []\n",
    "            pos = []\n",
    "            for idx in self.famvaridx[fam]:\n",
    "                names.append(self.variants[idx][0])\n",
    "                pos.append(self.variants[idx][1])\n",
    "            mafs = self.famvarmafs[fam]\n",
    "            return np.array(names), pos, np.array(mafs)  #pos can't be array -> TypeError: in method 'HaplotypingEngine_Execute'\n",
    "        else:\n",
    "            raise ValueError(\"Unknown style '{}'\".format(style))\n",
    "\n",
    "    def getFamSamples(self, fam):\n",
    "        nvar = len([item for idx, item in enumerate(self.variants) if idx in self.famvaridx[fam]])\n",
    "        output = [[]] * len(self.tfam.families[fam])\n",
    "        for idx, item in enumerate(self.tfam.sort_family(fam)):\n",
    "            # sample info, first 5 columns of ped\n",
    "            output[idx] = self.tfam.samples[item][:-1]\n",
    "            # sample genotypes\n",
    "            if item in self.samples:\n",
    "                output[idx].extend(self[item])\n",
    "            else:\n",
    "                output[idx].extend([\"00\"] * nvar)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.RegionExtractor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RegionExtractor:\n",
    "    '''Extract given genomic region from VCF\n",
    "    converting genotypes into dictionary of\n",
    "    genotype list'''\n",
    "    def __init__(self, filename, build = None, chr_prefix = None):\n",
    "        self.vcf = cstatgen.VCFstream(filename)\n",
    "        self.chrom = self.startpos = self.endpos = self.name = None\n",
    "        self.chr_prefix = chr_prefix\n",
    "        if build is None:\n",
    "            build = env.build\n",
    "        self.xchecker = PseudoAutoRegion('X', build)\n",
    "        self.ychecker = PseudoAutoRegion('Y', build)\n",
    "\n",
    "    def apply(self, data):\n",
    "        # Clean up\n",
    "        data.reset()\n",
    "        data.chrom = self.chrom\n",
    "        self.vcf.Extract(self.chrom, self.startpos, self.endpos)\n",
    "        if data.anno is None:\n",
    "            varIdx=self.extract_vcf(data)\n",
    "        else:\n",
    "            varIdx=self.extract_vcf_with_anno(data)\n",
    "        if varIdx == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            with env.variants_counter.get_lock():\n",
    "                env.variants_counter.value += varIdx\n",
    "            return 0\n",
    "\n",
    "    def extract_vcf(self,data):\n",
    "        varIdx = 0\n",
    "        # for each variant site\n",
    "        while (self.vcf.Next()):\n",
    "            # check if the line's sample number matches the entire VCF sample number\n",
    "            if not self.vcf.CountSampleGenotypes() == self.vcf.sampleCount:\n",
    "                raise ValueError('Genotype and sample mismatch for region {}: {:,d} vs {:,d}'.\\\n",
    "                             format(self.name, self.vcf.CountSampleGenotypes(), self.vcf.sampleCount))\n",
    "            # skip tri-allelic sites\n",
    "            if not self.vcf.IsBiAllelic():\n",
    "                with env.triallelic_counter.get_lock():\n",
    "                    env.triallelic_counter.value += 1\n",
    "                continue\n",
    "            # valid line found, get variant info\n",
    "            try:\n",
    "                maf = float(self.vcf.GetInfo(data.af_info))\n",
    "                if maf>0.5: #skip variants with af>0.5\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                env.log(\"VCF line {}:{} does not have valid allele frequency field {}!\".\\\n",
    "                                 format(self.vcf.GetChrom(), self.vcf.GetPosition(), data.af_info))\n",
    "                continue\n",
    "            \n",
    "            # for each family assign member genotype if the site is non-trivial to the family\n",
    "            for k in data.families:\n",
    "                gs = self.vcf.GetGenotypes(data.famsampidx[k])\n",
    "                if len(set(''.join([x for x in gs if x != \"00\"]))) <= 1:\n",
    "                    # skip monomorphic gs\n",
    "                    continue\n",
    "                else:\n",
    "                    # this variant is found in the family\n",
    "                    data.famvaridx[k].append(varIdx)\n",
    "                    data.famvarmafs[k].append(maf if maf < 0.5 else 1-maf)\n",
    "                    for person, g in zip(data.families[k], gs):\n",
    "                        data[person].append(g if maf<0.5 else self.reverse_genotypes(g))\n",
    "            data.variants.append([self.vcf.GetVariantID(), self.vcf.GetPosition(), self.name]) #remove maf\n",
    "            varIdx += 1\n",
    "        return varIdx\n",
    "\n",
    "    def extract_vcf_with_anno(self,data):\n",
    "        '''extract variants and annotation by region'''\n",
    "        if str(data.anno.Chr[0])!=self.chrom:\n",
    "            return 0\n",
    "        anno_idx = (data.anno.Start>=self.startpos) & (data.anno.Start<self.endpos)\n",
    "        if anno_idx.any()==False:\n",
    "            return 0\n",
    "        varmafs = data.anno[anno_idx]\n",
    "        varIdx = 0\n",
    "        i = -1\n",
    "        # for each variant site\n",
    "        while (self.vcf.Next()):\n",
    "            i += 1\n",
    "            # check if the line's sample number matches the entire VCF sample number\n",
    "            if not self.vcf.CountSampleGenotypes() == self.vcf.sampleCount:\n",
    "                raise ValueError('Genotype and sample mismatch for region {}: {:,d} vs {:,d}'.\\\n",
    "                             format(self.name, self.vcf.CountSampleGenotypes(), self.vcf.sampleCount))\n",
    "            # skip tri-allelic sites\n",
    "            if not self.vcf.IsBiAllelic():\n",
    "                with env.triallelic_counter.get_lock():\n",
    "                    env.triallelic_counter.value += 1\n",
    "                continue \n",
    "            # valid line found, get variant info\n",
    "            try:\n",
    "                mafs=varmafs.loc[self.vcf.GetVariantID()][2:]\n",
    "            except:\n",
    "                #print(self.vcf.GetVariantID(), 'is not in annotation')\n",
    "                continue\n",
    "            if mafs.any()==False:\n",
    "                continue\n",
    "            \n",
    "            # for each family assign member genotype if the site is non-trivial to the family\n",
    "            fam_mafs=[]\n",
    "            for k in data.families:\n",
    "                gs = self.vcf.GetGenotypes(data.famsampidx[k])\n",
    "                if len(set(''.join([x for x in gs if x != \"00\"]))) <= 1:\n",
    "                    # skip monomorphic gs\n",
    "                    continue\n",
    "                else:\n",
    "                    maf=mafs[data.fam_pop[k]]\n",
    "                    fam_mafs.append(maf)\n",
    "                    if maf and maf<0.5: #skip variants with af>0.5\n",
    "                        # this variant is found in the family\n",
    "                        data.famvaridx[k].append(varIdx)\n",
    "                        data.famvarmafs[k].append(maf if maf < 0.5 else 1-maf)\n",
    "                        for person, g in zip(data.families[k], gs):\n",
    "                            data[person].append(g if maf<0.5 else self.reverse_genotypes(g))\n",
    "            data.variants.append([self.vcf.GetVariantID(), self.vcf.GetPosition(), self.name]) #remove maf\n",
    "            #print(i,varmafs.shape,self.chrom, self.startpos, self.endpos, self.name,self.vcf.GetPosition())\n",
    "            varIdx += 1\n",
    "        return varIdx\n",
    "    \n",
    "    def check_gs(self,gs):\n",
    "        '''skip monomorphic variants and singleton variants in a family'''\n",
    "        cg={'00':0,'11':0, '12':0, '22':0}\n",
    "        for i in gs:\n",
    "            cg[i]+=1\n",
    "        not00 = cg['11']+cg['12']+cg['22']\n",
    "        if cg['11']==not00 or cg['12']==not00 or cg['22']==not00:\n",
    "            #skip monomorphic variants\n",
    "            return False\n",
    "        if cg['12']+cg['22']<=1:\n",
    "            #skip sington variants\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def reverse_genotypes(self,g):\n",
    "        ''' 11->22,12,21,22->11 '''\n",
    "        if g=='11':\n",
    "            g='22'\n",
    "        elif g=='22':\n",
    "            g='11'\n",
    "        return g\n",
    "\n",
    "    def getRegion(self, region):\n",
    "        self.chrom, self.startpos, self.endpos, self.name = region[:4]\n",
    "        self.startpos = int(self.startpos)\n",
    "        self.endpos = int(self.endpos) + 1\n",
    "        if self.chrom in ['X','23']:\n",
    "            if self.xchecker.check(self.startpos) or self.xchecker.check(self.endpos):\n",
    "                self.chrom = 'XY'\n",
    "        if self.chrom in ['Y','24']:\n",
    "            if self.ychecker.check(self.startpos) or self.ychecker.check(self.endpos):\n",
    "                self.chrom = 'XY'\n",
    "        if self.chr_prefix and not self.chrom.startswith(self.chr_prefix):\n",
    "            self.chrom = self.chr_prefix + self.chrom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.MarkerMaker class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MarkerMaker:\n",
    "    def __init__(self, wsize=1, maf_cutoff = None, recomb=False):\n",
    "        self.missings = (\"0\", \"0\")\n",
    "        self.gtconv = {'1':0, '2':1}\n",
    "        self.haplotyper = cstatgen.HaplotypingEngine(verbose = env.debug)\n",
    "        if wsize == 0 or wsize >= 1:\n",
    "            self.r2 = None\n",
    "        else:\n",
    "            self.r2 = wsize\n",
    "        self.coder = cstatgen.HaplotypeCoder(wsize)\n",
    "        self.maf_cutoff = maf_cutoff\n",
    "        self.rsq = 0.0\n",
    "        self.recomb = recomb\n",
    "    def getRegion(self, region):\n",
    "        self.name = region[3]\n",
    "        self.dtest = {}\n",
    "        self.dtest[self.name] = {}\n",
    "        self.dtest[self.name]['predata']={}\n",
    "\n",
    "    def apply(self, data):\n",
    "        #try:\n",
    "            # haplotyping plus collect found allele counts\n",
    "            # and computer founder MAFS\n",
    "        varnames,mafs,haplotypes=self.__Haplotype(data)\n",
    "        if len(varnames)==0:\n",
    "            return -1\n",
    "        if not any([len(varnames[x]) - 1 for x in varnames]):\n",
    "            # all families have only one variant\n",
    "            self.__AssignSNVHaplotypes(data, haplotypes, mafs, varnames)\n",
    "        else:\n",
    "            # calculate LD clusters using founder haplotypes\n",
    "            clusters = self.__ClusterByLD(data, haplotypes, varnames)\n",
    "            # recoding the genotype of the region\n",
    "            #env.dtest[self.name]['coder']['input'] = [data.copy(), haplotypes, mafs, varnames, clusters]\n",
    "            self.__CodeHaplotypes(data, haplotypes, mafs, varnames, clusters)\n",
    "            self.dtest[self.name]['maf']=data.maf\n",
    "            self.dtest[self.name]['hap']=self.haps\n",
    "            #env.dtest[self.name]['coder']['output'] = [self.coder.GetHaplotypes(),data.copy(),data.superMarkerCount,deepcopy(data.maf)]\n",
    "        #except Exception as e:\n",
    "        #    return -1\n",
    "        self.__FormatHaplotypes(data)\n",
    "        #env.dtest[self.name]['format'] = data.copy()\n",
    "        return 0\n",
    "\n",
    "    def __Haplotype(self, data):\n",
    "        '''genetic haplotyping. haplotypes stores per family data'''\n",
    "        # FIXME: it is SWIG's (2.0.12) fault not to properly destroy the object \"Pedigree\" in \"Execute()\"\n",
    "        # So there is a memory leak here which I tried to partially handle on C++\n",
    "        #\n",
    "        # Per family haplotyping\n",
    "        #\n",
    "        items = get_family_with_var(data)\n",
    "        with ProcessPoolExecutor(max_workers = 8) as executor:\n",
    "            inputs = executor.map(phasing_haps,repeat(data.chrom),items,[data.getFamVariants(item, style = \"map\") for item in items],[data.getFamSamples(item) for item in items])\n",
    "        \n",
    "        varnames,mafs,haplotypes = OrderedDict(),OrderedDict(),OrderedDict()\n",
    "        for item,item_varnames,item_mafs,item_haplotypes in inputs:\n",
    "            if len(item_haplotypes) == 0:\n",
    "                # C++ haplotyping implementation failed\n",
    "                with env.chperror_counter.get_lock():\n",
    "                    env.chperror_counter.value += 1\n",
    "                    env.log('{} family failed to phase haplotypes.'.format(item))\n",
    "                for person in data.families[item]:\n",
    "                    data[person] = self.missings\n",
    "                    continue\n",
    "            self.dtest[self.name]['predata'][item]=[item_varnames,item_mafs,item_haplotypes]\n",
    "            # Drop some variants if maf is greater than given threshold\n",
    "            if self.maf_cutoff is not None:\n",
    "                keep_idx = item_mafs<self.maf_cutoff\n",
    "                if not keep_idx.any():\n",
    "                    for person in data.families[item]:\n",
    "                        data[person] = self.missings\n",
    "                    continue\n",
    "                item_mafs = item_mafs[keep_idx]\n",
    "                item_varnames = item_varnames[keep_idx]\n",
    "                item_haplotypes = item_haplotypes[:,np.concatenate(([True,True],keep_idx))]\n",
    "            varnames[item],mafs[item],haplotypes[item]= item_varnames,item_mafs,item_haplotypes\n",
    "        return varnames,mafs,haplotypes\n",
    "          \n",
    "\n",
    "    def __ClusterByLD(self, data, haplotypes, varnames):\n",
    "        if self.r2 is None:\n",
    "            return None\n",
    "        # get founder haplotypes\n",
    "        founder_haplotypes = []\n",
    "        markers = sorted(set(itertools.chain(*varnames.values())), key = lambda x: int(x.split(\"-\")[0][1:]))\n",
    "        for item in haplotypes:\n",
    "            for ihap, hap in enumerate(haplotypes[item]):\n",
    "                if not data.tfam.is_founder(hap[1]):\n",
    "                    continue\n",
    "                gt = [hap[2 + list(varnames[item]).index(v)] if v in varnames[item] else '?' for v in markers]\n",
    "                founder_haplotypes.append((\"{}-{}\".format(hap[1], ihap % 2), \"\".join([x[1] if x[0].isupper() else x[0] for x in gt])))\n",
    "        # calculate LD blocks, use r2 measure\n",
    "        blocks = []\n",
    "        if sys.version_info.major == 2:\n",
    "            ld = Align.create(founder_haplotypes).matrixLD(validCharacters=\"12\")[\"r2\"]\n",
    "            for j in ld:  #upper triangle\n",
    "                block = [j]\n",
    "                for k in ld[j]:\n",
    "                    try:\n",
    "                        if ld[j][k] > self.r2:\n",
    "                            block.append(k)\n",
    "                    except:\n",
    "                        print('ld value',ld[j][k])\n",
    "                if len(block) > 1:\n",
    "                    blocks.append(block)\n",
    "        else:\n",
    "            ldi,ld = egglib.stats.matrix_LD(Align.create(founder_haplotypes,egglib.Alphabet(cat='string',expl=['1','2'],miss='?')),('rsq'))\n",
    "            for j in range(len(ldi)): #lower triangle\n",
    "                block = [j]\n",
    "                for k in range(j+1,len(ldi)):\n",
    "                    try:\n",
    "                        if ld[k][j] > self.r2:\n",
    "                            block.append(k)\n",
    "                    except:\n",
    "                        print('ld value',ld[k][j])\n",
    "                if len(block) > 1:\n",
    "                    blocks.append(block)\n",
    "        # get LD clusters\n",
    "        clusters = [[markers[idx] for idx in item] for item in list(connected_components(blocks))]\n",
    "        #env.dtest[self.name]['ld'] = [ld,blocks,clusters]\n",
    "        if env.debug:\n",
    "            with env.lock:\n",
    "                print(\"LD blocks: \", blocks, file = sys.stderr)\n",
    "                print(\"LD clusters: \", clusters, file = sys.stderr)\n",
    "        return clusters\n",
    "\n",
    "\n",
    "    def __CodeHaplotypes(self, data, haplotypes, mafs, varnames, clusters):\n",
    "        # apply CHP coding\n",
    "        if clusters is not None:\n",
    "            clusters_idx = [[[list(varnames[item]).index(x) for x in y if x in varnames[item]] for y in clusters] for item in haplotypes]\n",
    "        else:\n",
    "            clusters_idx = [[[]] for item in haplotypes]\n",
    "        self.coder.Execute(list(haplotypes.values()), [mafs[item] for item in haplotypes], clusters_idx,self.recomb)\n",
    "        if env.debug:\n",
    "            with env.lock:\n",
    "                if clusters:\n",
    "                    print(\"Family LD clusters: \", clusters_idx, \"\\n\", file = sys.stderr)\n",
    "                self.coder.Print()\n",
    "        # line: [fid, sid, hap1, hap2]\n",
    "        self.haps = {}\n",
    "        for line in self.coder.GetHaplotypes():\n",
    "            #if not line[1] in data:\n",
    "                # this sample is not in VCF file. Every variant site should be missing\n",
    "                # they have to be skipped for now\n",
    "            #    continue\n",
    "            data[line[1]] = (line[2].split(','), line[4].split(','))\n",
    "            self.haps[line[0]] = self.haps.get(line[0], line)\n",
    "            if len(data[line[1]][0]) > data.superMarkerCount:\n",
    "                data.superMarkerCount = len(data[line[1]][0])\n",
    "        # get MAF\n",
    "        for item in haplotypes:\n",
    "            data.maf[item] = self.coder.GetAlleleFrequencies(item)\n",
    "            data.maf[item] = tuple(tuple(np.array(v) / np.sum(v)) if np.sum(v) else v\n",
    "                              for v in data.maf[item])\n",
    "        if env.debug:\n",
    "            with env.lock:\n",
    "                print(\"marker freqs = \", data.maf, \"\\n\", file = sys.stderr)\n",
    "\n",
    "\n",
    "    def __AssignSNVHaplotypes(self, data, haplotypes, mafs, varnames):\n",
    "        print('SNVHap',self.name)\n",
    "        for item in haplotypes:\n",
    "            # each person's haplotype\n",
    "            token = ''\n",
    "            for idx, line in enumerate(haplotypes[item]):\n",
    "                if not idx % 2:\n",
    "                    token = line[2][1] if line[2][0].isupper() else line[2][0]\n",
    "                else:\n",
    "                    data[line[1]] = (token, line[2][1] if line[2][0].isupper() else line[2][0])\n",
    "            # get maf\n",
    "            data.maf[item] = [(1 - mafs[item][0], mafs[item][0])]\n",
    "            data.maf[item] = tuple(tuple(np.array(v) / np.sum(v)) if np.sum(v) else v\n",
    "                              for v in data.maf[item])\n",
    "        if env.debug:\n",
    "            with env.lock:\n",
    "                print(\"marker freqs = \", data.maf, \"\\n\", file = sys.stderr)\n",
    "\n",
    "\n",
    "    def __FormatHaplotypes(self, data):\n",
    "        # Reformat sample genotypes\n",
    "        for person in data:\n",
    "            if type(data[person]) is not tuple:\n",
    "                data[person] = self.missings\n",
    "                continue\n",
    "            diff = data.superMarkerCount - len(data[person][0])\n",
    "            data[person] = list(zip(*data[person]))\n",
    "            if diff > 0:\n",
    "                data[person].extend([self.missings] * diff)\n",
    "\n",
    "    def __PedToHaplotype(self, ped):\n",
    "        '''convert prephased ped format to haplotype format.\n",
    "        Input: e.g. [['13346', '5888', '0', '0', '1', '11', '11', '11'], ['13346', '5856', '0', '0', '2', '12', '12', '12'], ['13346', '5920', '5888', '5856', '1', '12', '12', '12'], ['13346', '6589', '5888', '5856', '1', '11', '11', '11']]\n",
    "        Output: e.g. (('13346', '5856', '1:', '1:', '1:'), ('13346', '5856', '2:', '2:', '2:'), ('13346', '5888', '1:', '1:', '1:'), ('13346', '5888', '1:', '1:', '1:'), ('13346', '6589', '1:', '1|', '1|'), ('13346', '6589', '1:', '1|', '1|'), ('13346', '5920', '2:', '2|', '2|'), ('13346', '5920', '1:', '1|', '1|'))\n",
    "        '''\n",
    "        haps = []\n",
    "        for item in ped:\n",
    "            entry = [item[0], item[1]] + [x[0] + ':' if x[0] != '0' else '?:' for x in item[5:]]\n",
    "            haps.append(tuple(entry))\n",
    "            entry = [item[0], item[1]] + [x[1] + ':' if x[1] != '0' else '?:' for x in item[5:]]\n",
    "            haps.append(tuple(entry))\n",
    "        return tuple(haps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for `__Haplotype`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_family_with_var(data):\n",
    "    items = []\n",
    "    for item,item_vars in data.famvaridx.items():\n",
    "        if len(item_vars) == 0:  #no variants in the family\n",
    "            for person in data.families[item]:\n",
    "                data[person] = (\"0\", \"0\")\n",
    "        else:\n",
    "            items.append(item)\n",
    "    return items\n",
    "\n",
    "haplotyper = cstatgen.HaplotypingEngine(verbose = env.debug)\n",
    "def phasing_haps(chrom,item,fvar,fgeno):\n",
    "    item_varnames, positions, item_mafs = fvar\n",
    "    try:\n",
    "        item_haplotypes = haplotyper.Execute(chrom, item_varnames, positions, fgeno)[0]\n",
    "    except:\n",
    "        env.log(\"{} fail to phase haplotypes\".format(item))\n",
    "        item_haplotypes = []\n",
    "    item_haplotypes = np.array(item_haplotypes)\n",
    "    return item,item_varnames,item_mafs,item_haplotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.LinkageWriter class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LinkageWriter:\n",
    "    def __init__(self, num_missing_append = 0):\n",
    "        self.chrom = self.prev_chrom = self.name = self.distance = self.distance_avg = self.distance_m = self.distance_f = None\n",
    "        self.reset()\n",
    "        self.missings = [\"0\", \"0\"]\n",
    "        self.num_missing = num_missing_append\n",
    "\n",
    "    def apply(self, data):   \n",
    "        if self.chrom != self.prev_chrom:\n",
    "            if self.prev_chrom is None:\n",
    "                self.prev_chrom = self.chrom\n",
    "            else:\n",
    "                # new chrom entered,\n",
    "                # commit whatever is in buffer before accepting new data\n",
    "                self.commit()\n",
    "        # write tped output\n",
    "        position = str(data.getMidPosition())\n",
    "        if data.superMarkerCount <= 1:\n",
    "            # genotypes\n",
    "            gs = [data[s][0] for s in data.tfam.samples]\n",
    "            if len(set(gs)) == 1:\n",
    "                # everyone's genotype is the same (most likely missing or monomorphic)\n",
    "                return 2\n",
    "            self.tped += env.delimiter.join([self.chrom, self.name, self.distance, position] + \\\n",
    "                list(itertools.chain(*gs)) + self.missings*self.num_missing) + \"\\n\"\n",
    "            # freqs\n",
    "            for k in data.maf:\n",
    "                self.freq += env.delimiter.join([k, self.name] + list(map(str, data.maf[k][0]))) + \"\\n\"\n",
    "        else:\n",
    "            # have to expand each region into mutiple chunks to account for different recomb points\n",
    "            gs = list(zip(*[data[s] for s in data.tfam.samples]))\n",
    "            # sub-chunk id\n",
    "            cid = 0\n",
    "            skipped_chunk = []\n",
    "            for idx, g in enumerate(gs):\n",
    "                if len(set(g)) == 1:\n",
    "                    skipped_chunk.append(idx)\n",
    "                    continue\n",
    "                cid += 1\n",
    "                self.tped += \\\n",
    "                  env.delimiter.join([self.chrom, '{}[{}]'.format(self.name, cid), self.distance, position] + \\\n",
    "                  list(itertools.chain(*g)) + self.missings*self.num_missing) + \"\\n\"\n",
    "            if cid == 0:\n",
    "                # everyone's genotype is the same (most likely missing or monomorphic)\n",
    "                return 2\n",
    "            # freqs\n",
    "            for k in data.maf:\n",
    "                cid = 0\n",
    "                for idx in range(data.superMarkerCount):\n",
    "                    if idx in skipped_chunk:\n",
    "                        continue\n",
    "                    if idx >= len(data.maf[k]):\n",
    "                        break\n",
    "                    cid += 1\n",
    "                    self.freq += env.delimiter.join([k, '{}[{}]'.format(self.name, cid)] + \\\n",
    "                                                    list(map(str, data.maf[k][idx]))) + \"\\n\"\n",
    "        if self.counter < env.batch:\n",
    "            self.counter += data.superMarkerCount\n",
    "        else:\n",
    "            self.commit()\n",
    "        return 0\n",
    "\n",
    "    def commit(self):\n",
    "        if self.tped:\n",
    "            with env.lock:\n",
    "                with open(os.path.join(env.tmp_cache, '{}.chr{}.tped'.format(env.output, self.prev_chrom)),\n",
    "                          'a') as f:\n",
    "                    f.write(self.tped)\n",
    "        if self.freq:\n",
    "            with env.lock:\n",
    "                with open(os.path.join(env.tmp_cache, '{}.chr{}.freq'.format(env.output, self.prev_chrom)),\n",
    "                          'a') as f:\n",
    "                    f.write(self.freq)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.tped = ''\n",
    "        self.freq = ''\n",
    "        self.counter = 0\n",
    "        self.prev_chrom = self.chrom\n",
    "\n",
    "    def getRegion(self, region):\n",
    "        self.chrom, self.startpos, self.endpos, self.name = region[:4]\n",
    "        if len(region)>4:\n",
    "            self.distance_avg, self.distance_m, self.distance_f = region[4:]\n",
    "            self.distance = \";\".join([self.distance_avg, self.distance_m, self.distance_f])\n",
    "        else:\n",
    "            self.distance = \".\"\n",
    "        \n",
    "class EncoderWorker(Process):\n",
    "    def __init__(self, queue, length, data, extractor, coder, writer):\n",
    "        Process.__init__(self)\n",
    "        self.queue = queue\n",
    "        self.numGrps = float(length)\n",
    "        self.data = data\n",
    "        self.extractor = extractor\n",
    "        self.maker = coder\n",
    "        self.writer = writer\n",
    "\n",
    "    def report(self):\n",
    "        env.log('{:,d} units processed {{{:.2%}}} ...'.\\\n",
    "                format(env.success_counter.value, env.total_counter.value / self.numGrps), flush = True)\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            try:\n",
    "                region = self.queue.pop(0) if isinstance(self.queue, list) else self.queue.get()\n",
    "                if region is None:\n",
    "                    self.writer.commit()\n",
    "                    self.report()\n",
    "                    # total mendelian errors found\n",
    "                    with env.mendelerror_counter.get_lock():\n",
    "                        env.mendelerror_counter.value += self.maker.haplotyper.CountMendelianErrors()\n",
    "                    # total recombination events found\n",
    "                    with env.recomb_counter.get_lock():\n",
    "                        env.recomb_counter.value += self.maker.coder.CountRecombinations()\n",
    "                    break\n",
    "                else:\n",
    "                    with env.total_counter.get_lock():\n",
    "                        env.total_counter.value += 1\n",
    "                    self.extractor.getRegion(region)\n",
    "                    self.writer.getRegion(region)\n",
    "                    self.maker.getRegion(region)\n",
    "                    isSuccess = True\n",
    "                    for m in [self.extractor, self.maker, self.writer]:\n",
    "                        status = m.apply(self.data)\n",
    "                        if status == -1:\n",
    "                            with env.chperror_counter.get_lock():\n",
    "                                # previous module failed\n",
    "                                env.chperror_counter.value += 1\n",
    "                        if status == 1:\n",
    "                            with env.null_counter.get_lock():\n",
    "                                env.null_counter.value += 1\n",
    "                        if status == 2:\n",
    "                            with env.trivial_counter.get_lock():\n",
    "                                env.trivial_counter.value += 1\n",
    "                        if status != 0:\n",
    "                            isSuccess = False\n",
    "                            break\n",
    "                    if isSuccess:\n",
    "                        with env.success_counter.get_lock():\n",
    "                            env.success_counter.value += 1\n",
    "                    if env.total_counter.value % (env.batch * env.jobs) == 0:\n",
    "                        self.report()\n",
    "            except KeyboardInterrupt:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Run linagke analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def run_each_region(regions,data,extractor,maker,writer,runlinkage=True,cutoff=1.0,chp=True,rho=np.arange(0,0.5,0.05),model = \"AD\",chrom = \"AUTOSOMAL\",penetrances = [0.01,0.9,0.9],dfreq=0.001):\n",
    "    '''get the haplotypes and allele frequency of variants in each region and run linkage analysis'''\n",
    "    results = {}\n",
    "    i=0\n",
    "    output_chr='chr'+str(data.anno.Chr.unique()[0])+'result' if data.anno is not None and len(data.anno.Chr.unique())==1 else 'chrallresult'\n",
    "    os.makedirs(os.path.join(env.outdir,output_chr), exist_ok=True)\n",
    "    start = time.perf_counter()\n",
    "    for region in regions:\n",
    "        extractor.getRegion(region)\n",
    "        maker.getRegion(region)\n",
    "        writer.getRegion(region)\n",
    "        isSuccess = True\n",
    "        for m in [extractor, maker, writer] if chp else [extractor]:\n",
    "            status = m.apply(data)\n",
    "            if status == -1:\n",
    "                with env.chperror_counter.get_lock():\n",
    "                    # previous module failed\n",
    "                    env.chperror_counter.value += 1\n",
    "            if status == 1:\n",
    "                with env.null_counter.get_lock():\n",
    "                    env.null_counter.value += 1\n",
    "            if status == 2:\n",
    "                with env.trivial_counter.get_lock():\n",
    "                    env.trivial_counter.value += 1\n",
    "            if status != 0:\n",
    "                isSuccess = False\n",
    "                break\n",
    "        if isSuccess:\n",
    "            with env.success_counter.get_lock():\n",
    "                env.success_counter.value += 1\n",
    "            if chp:\n",
    "                results[region[3]]=maker.dtest[region[3]]\n",
    "            else:\n",
    "                #{'gene':{'predata':{'fam':[snp_ids,freq,genos]}}}\n",
    "                items = get_family_with_var(data)\n",
    "                predata={}\n",
    "                for item in items:\n",
    "                    fvar=data.getFamVariants(item, style = \"map\")\n",
    "                    fgeno=np.array(data.getFamSamples(item))\n",
    "                    predata[item]=[fvar[0],fvar[2],fgeno]\n",
    "                results[region[3]]={'predata':predata}\n",
    "                \n",
    "            if len(results)==env.cache_size:\n",
    "                gene_genotype_file=os.path.join(env.outdir,output_chr,output_chr+str(i)+'.pickle')\n",
    "                env.log('write to pickle: '+gene_genotype_file+',Gene number:'+str(len(results))+',Time:'+str((time.perf_counter()-start)/3600))\n",
    "                start = time.perf_counter()\n",
    "                with open(gene_genotype_file, 'wb') as handle:\n",
    "                    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                results = {}\n",
    "                i +=1\n",
    "                if runlinkage: #linkage analysis\n",
    "                    linkage_analysis(gene_genotype_file,data.fam,data.fam_vcf,cutoff,chp,rho,model,chrom,penetrances,dfreq)\n",
    "    if len(results)>0:\n",
    "        gene_genotype_file=os.path.join(env.outdir,output_chr,output_chr+str(i)+'.pickle')\n",
    "        env.log('write to pickle: '+gene_genotype_file+',Gene number:'+str(len(results))+',Time:'+str((time.perf_counter()-start)/3600))\n",
    "        with open(gene_genotype_file, 'wb') as handle:\n",
    "            pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        results = {}    \n",
    "    if runlinkage:#linkage analysis\n",
    "        linkage_analysis(gene_genotype_file,data.fam,data.fam_vcf,cutoff,chp,rho,model,chrom,penetrances,dfreq)\n",
    "        summarize_lods(gene_genotype_file[:-8]+'*_linkage.lods',os.path.join(env.outdir,output_chr),regions,phase=chp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
