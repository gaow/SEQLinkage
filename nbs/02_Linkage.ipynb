{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9db215-ae12-49ae-ab04-e7bb662bb62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp Linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1aacf4-ab3a-4791-bf29-22350e1c0e34",
   "metadata": {},
   "source": [
    "# Linkage module\n",
    "\n",
    "> The core functions for linkage analysis. Paramlink2 is used to do linkage analysis. The R code is bridged to python through rpy2. It run linkage analysis from batch to batch (default is 25 genes per batch). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dbd966-53ad-4300-b074-03016a5fc35e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "import os.path\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import repeat\n",
    "import numbers\n",
    "\n",
    "#Import necessary packages\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "base = importr('base')\n",
    "base.options(expressions = 5e5)\n",
    "#Must be activated\n",
    "pandas2ri.activate()\n",
    "paramlink2=importr('paramlink2')\n",
    "pedprobr=importr('pedprobr')\n",
    "pedtools = importr('pedtools')\n",
    "\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor,ThreadPoolExecutor\n",
    "from scipy.optimize import minimize_scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bd1652-046e-4523-870a-1cce6ff79626",
   "metadata": {},
   "source": [
    "### Functions for preprocessing genotypes or phased haplotypes\n",
    "- input haps\n",
    "- output preprocessed inputs of chp markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36178fbc-b342-49a8-a9c2-872fb62937c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_haps_ped(genes):\n",
    "    gpeds={}\n",
    "    for g,fs in genes.items():\n",
    "        fs=fs['predata']\n",
    "        tmp={}\n",
    "        for f,v in fs.items():\n",
    "            tmp[f]=hap2chp(v,g)\n",
    "        if len(tmp)>0:\n",
    "            gpeds[g]={}\n",
    "            gpeds[g]['predata']=tmp\n",
    "    return gpeds\n",
    "\n",
    "def hap2chp(haps,gene):\n",
    "    '''input hap is [varnames,freqs,halpotypes]\n",
    "       output is [chp_varnames,chp_freqs,chps]\n",
    "    '''\n",
    "    if len(haps[0])>1:\n",
    "        hap=haps[2][:,2:]\n",
    "        rec=recombination_pos(hap)\n",
    "        new_hap=[]\n",
    "        for genos in hap:\n",
    "            new_genos=[]\n",
    "            for i,j in zip(rec[:-1],rec[1:]):\n",
    "                new_genos.append(generate_marker(np.array([get_allele(x) for x in genos[i:j]])))\n",
    "            new_hap.append(new_genos)\n",
    "        new_hap=np.concatenate([haps[2][:,:2],np.array(new_hap)],axis=1)\n",
    "        variants=np.array([gene+':'+str(i) for i in range(len(rec)-1)])\n",
    "        mafs=np.array([1-np.prod(1-haps[1][i:j]) for i,j in zip(rec[:-1],rec[1:])])\n",
    "    else:\n",
    "        variants,mafs,new_hap=np.array([gene+':0']),haps[1],haps[2]\n",
    "    return [variants,mafs,new_hap]\n",
    "\n",
    "def generate_marker(alleles):\n",
    "    '''array of 0,1,2. 0 if all 0 -> 2 if any 2 else 1'''\n",
    "    if np.all(alleles==0):\n",
    "        return '0:'\n",
    "    elif np.any(alleles==2):\n",
    "        return '2:'\n",
    "    else:\n",
    "        return '1:'\n",
    "\n",
    "def recombination_pos(hap):\n",
    "    rec = [0,hap.shape[1]-1]\n",
    "    for genos in hap:\n",
    "        for c,geno in enumerate(genos):\n",
    "            if geno[-1] not in [':','|']:\n",
    "                rec.append(c)\n",
    "    return list(set(rec))\n",
    "def recombination_region(hap):\n",
    "    rec=recombination_pos(hap)\n",
    "    return [(i,j) for i,j in zip(rec[:-1],rec[1:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a482dec5-b400-4421-b5c5-de3b1e2c3262",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672371f0-73e1-494b-90d0-c518524c6d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/wg20220311/chr19test/CACHE/chr19test43.pickle', 'rb') as handle:\n",
    "    genes = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e230f-7d5e-4c5d-9285-ee00db7fc702",
   "metadata": {},
   "outputs": [],
   "source": [
    "haps=genes['APOE']['predata']['1007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd60c1c-8435-428d-96d9-139a079f53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap=haps[2][:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952a16d-3d91-4fdb-9648-1d1844ae5149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2:', '1:', 'A1,2:', '1:'],\n",
       "       ['2:', '2:', '1:', '2:'],\n",
       "       ['1:', '1:', 'A2,1:', '1:'],\n",
       "       ['2:', '2:', '1:', '2:'],\n",
       "       ['2:', '1:', 'A1,2:', '1:'],\n",
       "       ['?:', '?:', '?:', '?:'],\n",
       "       ['2:', '1/', 'A2,1|', '1\\\\'],\n",
       "       ['2:', '1/', 'A1,2|', '2\\\\'],\n",
       "       ['2:', '2|', '1|', '2|'],\n",
       "       ['2:', '2|', '1|', '2|'],\n",
       "       ['1:', '1|', 'A2,1|', '1|'],\n",
       "       ['2:', '1|', 'A1,2|', '1|'],\n",
       "       ['1:', '1|', 'A2,1|', '1|'],\n",
       "       ['2:', '1|', 'A1,2|', '1|'],\n",
       "       ['1:', '1|', 'A2,1|', '1|'],\n",
       "       ['2:', '1|', 'A1,2|', '1|'],\n",
       "       ['1:', '1|', 'A2,1|', '1|'],\n",
       "       ['2:', '1|', 'A1,2|', '1|']], dtype='<U7')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1d1f4b-f35f-4b93-89d8-01ebd9de9316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recombination_pos(hap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaecf59-1264-4c27-8cb6-95672495f684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 3)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recombination_region(hap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a53afd0-1e90-443c-a9cd-d28d3f6e03a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['APOE:0', 'APOE:1'], dtype='<U6'),\n",
       " array([0.4113    , 0.37500985]),\n",
       " array([['1007', '1007_1', '2:', '1:'],\n",
       "        ['1007', '1007_1', '2:', '2:'],\n",
       "        ['1007', '1007_2', '1:', '2:'],\n",
       "        ['1007', '1007_2', '2:', '2:'],\n",
       "        ['1007', '1007_40', '2:', '1:'],\n",
       "        ['1007', '1007_40', '0:', '0:'],\n",
       "        ['1007', '1007_99', '2:', '2:'],\n",
       "        ['1007', '1007_99', '2:', '1:'],\n",
       "        ['1007', '1007_5', '2:', '2:'],\n",
       "        ['1007', '1007_5', '2:', '2:'],\n",
       "        ['1007', '1007_3', '1:', '2:'],\n",
       "        ['1007', '1007_3', '2:', '1:'],\n",
       "        ['1007', '1007_6', '1:', '2:'],\n",
       "        ['1007', '1007_6', '2:', '1:'],\n",
       "        ['1007', '1007_4', '1:', '2:'],\n",
       "        ['1007', '1007_4', '2:', '1:'],\n",
       "        ['1007', '1007_39', '1:', '2:'],\n",
       "        ['1007', '1007_39', '2:', '1:']], dtype='<U7')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hap2chp(haps,'APOE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6e618c-3014-4abd-8a09-5c2026cd4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/wg20220725raretrimmed_phase/chr22test/tmp/CACHE/chr22test0.pickle', 'rb') as handle:\n",
    "    genes1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5aa08-0ba3-4028-aeb0-86255ad945a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['chr22:15690532:A:G'], dtype='<U18'),\n",
       " array([0.0021]),\n",
       " array([['10J_128:0:0', '10J_128_7', '1:'],\n",
       "        ['10J_128:0:0', '10J_128_7', '1:'],\n",
       "        ['10J_128:0:0', '10J_128_227', '2:'],\n",
       "        ['10J_128:0:0', '10J_128_227', '?:'],\n",
       "        ['10J_128:0:0', '10J_128_111', '1:'],\n",
       "        ['10J_128:0:0', '10J_128_111', '2:']], dtype='<U11')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes1['POTEH']['predata']['10J_128:0:0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6060fa56-17d2-4a02-b6fd-28e52935278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=update_haps_ped(genes1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddf95fc-ccd9-40c3-8507-b898b976ddd8",
   "metadata": {},
   "source": [
    "### Functions for formating the input of linkage analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f878ff8-8148-480c-aec9-51c8fe333e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_allele(s):\n",
    "    a = s[1] if s[0].isupper() else s[0]\n",
    "    return 0 if a=='?' else int(a)\n",
    "\n",
    "def name_haps(snps):\n",
    "    name = []\n",
    "    for i in snps:\n",
    "        name += [i+'_A0',i+'_A1']\n",
    "    return name\n",
    "\n",
    "def get_fam_hap(haps,variants,vcf=None):\n",
    "    new_haps,new_iid = [],[]\n",
    "    iid = haps[:,1]\n",
    "    haps = haps[:,2:]\n",
    "    for i in range(0,haps.shape[0],2):\n",
    "        cur_iid=iid[i]\n",
    "        new_iid.append(cur_iid)\n",
    "        if vcf is None or vcf[cur_iid]:#have vcf\n",
    "            hap_a01 = []\n",
    "            for a0,a1 in zip(haps[i],haps[i+1]): #loop through variants\n",
    "                hap_a01 += [get_allele(a0),get_allele(a1)]\n",
    "        else:\n",
    "            hap_a01 = [0,0]*haps.shape[1] #set missing vcf to 0\n",
    "        new_haps.append(hap_a01)\n",
    "    new_haps = pd.DataFrame(new_haps)\n",
    "    new_haps.index = new_iid\n",
    "    new_haps.columns = name_haps(variants)\n",
    "    #remove variants with only 1 or 2 as alleles, return None\n",
    "    idx=[]\n",
    "    for i in range(0,new_haps.shape[1],2):\n",
    "        v=set(new_haps.iloc[:,i]).union(set(new_haps.iloc[:,i+1]))\n",
    "        if 1 not in v or 2 not in v:\n",
    "            idx.append(False)\n",
    "        else:\n",
    "            idx.append(True)\n",
    "    if sum(idx)==0:\n",
    "        return None\n",
    "    return new_haps.loc[:,np.repeat(np.array(idx),2)],idx\n",
    "\n",
    "def get_fam_geno(haps,variants,vcf=None):\n",
    "    new_haps,new_iid = [],[]\n",
    "    iid = haps[:,1]\n",
    "    haps = haps[:,5:]\n",
    "    for i in range(haps.shape[0]):\n",
    "        cur_iid=iid[i]\n",
    "        new_iid.append(cur_iid)\n",
    "        if vcf is None or vcf[cur_iid]:#have vcf\n",
    "            hap_a01 = []\n",
    "            for a01 in haps[i]: #loop through variants\n",
    "                hap_a01 += [int(a) for a in a01]\n",
    "        else:\n",
    "            hap_a01 = [0,0]*haps.shape[1] #set missing vcf to 0\n",
    "        new_haps.append(hap_a01)\n",
    "    new_haps = pd.DataFrame(new_haps)\n",
    "    new_haps.index = new_iid\n",
    "    new_haps.columns = name_haps(variants)\n",
    "    #remove variants with only 1 or 2 as alleles, return None\n",
    "    idx=[]\n",
    "    for i in range(0,new_haps.shape[1],2):\n",
    "        v=set(new_haps.iloc[:,i]).union(set(new_haps.iloc[:,i+1]))\n",
    "        if 1 not in v or 2 not in v:\n",
    "            idx.append(False)\n",
    "        else:\n",
    "            idx.append(True)\n",
    "    if sum(idx)==0:\n",
    "        return None\n",
    "    return new_haps.loc[:,np.repeat(np.array(idx),2)],idx\n",
    "\n",
    "def format_haps_bunch(dhaps,fam,vcfs=None,cutoff=None,haplotype=True):\n",
    "    gene_variants = {}\n",
    "    gene_haps = {}\n",
    "    for g in dhaps.keys():\n",
    "        haps = dhaps[g]['predata']\n",
    "        with ProcessPoolExecutor(max_workers = 10) as executor:\n",
    "            if haplotype:\n",
    "                results = executor.map(get_fam_hap,[haps[k][2] for k in haps.keys()],[haps[k][0] for k in haps.keys()],[vcfs[k] if vcfs else None for k in haps.keys()])\n",
    "            else:\n",
    "                results = executor.map(get_fam_geno,[haps[k][2] for k in haps.keys()],[haps[k][0] for k in haps.keys()],[vcfs[k] if vcfs else None for k in haps.keys()])\n",
    "        for f,hap in  zip(haps.keys(),results):\n",
    "            if hap is None: #remove only have 1 or 2 variants\n",
    "                continue\n",
    "            if f not in gene_variants.keys():\n",
    "                gene_variants[f] = {'genes':[],'variants':[],'freqs':[]}\n",
    "                gene_haps[f] = hap[0]\n",
    "            else:\n",
    "                gene_haps[f] = pd.concat([gene_haps[f],hap[0]],axis=1)\n",
    "            idx=hap[1] #False for variants only have 1 or 2.\n",
    "            gene_variants[f]['genes'] += [g]*sum(idx)\n",
    "            gene_variants[f]['variants'] += list(haps[f][0][idx])\n",
    "            gene_variants[f]['freqs'] += list(haps[f][1][idx])\n",
    "    new_gene_variants,new_gene_haps={},{}\n",
    "    for i,j in gene_variants.items():\n",
    "        j=pd.DataFrame(j)\n",
    "        if cutoff is not None:\n",
    "            frq_idx=np.array(j['freqs'])>cutoff\n",
    "            if frq_idx.any()==False:\n",
    "                continue\n",
    "            j=j.loc[frq_idx,:]\n",
    "            gene_haps[i]=gene_haps[i].loc[:,np.repeat(frq_idx,2)] \n",
    "        redup_idx = ~gene_haps[i].columns.duplicated()\n",
    "        new_gene_haps[i] = pd.concat([fam[i],gene_haps[i].iloc[:,redup_idx]],axis=1)\n",
    "        j['uniq'] = list(redup_idx[range(0,len(redup_idx),2)])\n",
    "        new_gene_variants[i] = j\n",
    "    return new_gene_variants,new_gene_haps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc75963-7c07-483a-b51d-088dbdc3e52a",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c507a-38c0-4c5f-9cd2-5af554fb2b4e",
   "metadata": {},
   "source": [
    "### Functions of heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f0c19-ba55-49d7-838b-624856008fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hlod_fun(Li, sign=1):\n",
    "    def _fun(alpha):\n",
    "        return sign * sum(np.log10(alpha*np.power(10, Li) + 1 - alpha))\n",
    "    return _fun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a07bb9-8349-46f0-bd26-89ca707d373a",
   "metadata": {},
   "source": [
    "### Functions for linkage analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26050faf-dcd4-4e4b-97b1-99b0fd508a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_ped_lod(ped,afreq=None,rho=0,model = \"AD\",chrom = \"AUTOSOMAL\",penetrances = [0.01,0.9,0.9],dfreq=0.001):\n",
    "    def _calculate_ped_lod(mped, aff, model,rho):\n",
    "        res = paramlink2.lod(mped, aff, model,rho)\n",
    "        try:\n",
    "            res = pd.DataFrame(res)[['MARKER','LOD']]\n",
    "        except:\n",
    "            res = pd.DataFrame([[ped.columns[6],res[0]]],columns=['MARKER','LOD'])\n",
    "        return res\n",
    "    aff=ped.iloc[:,5]\n",
    "    mped = pedtools.as_ped(ped.drop(ped.columns[5], axis=1),famid_col = 1,id_col = 2,fid_col = 3,mid_col = 4,sex_col = 5)\n",
    "    if afreq is not None:\n",
    "        mped = pedtools.setLocusAttributes(mped,locusAttributes=[base.list(afreq=base.c(1-i,i)) for i in afreq])\n",
    "    modAD = paramlink2.diseaseModel(model,chrom,pd.Series(penetrances),dfreq)\n",
    "    if isinstance(rho,numbers.Number):\n",
    "        res = _calculate_ped_lod(mped, aff = aff, model = modAD,rho=rho)\n",
    "    else:\n",
    "        res=None\n",
    "        for r in rho:\n",
    "            tmp = _calculate_ped_lod(mped, aff = aff, model = modAD,rho=r)\n",
    "            if res is None:\n",
    "                res=tmp\n",
    "                res.columns = ['MARKER','LOD'+str(round(r,2))]\n",
    "            else:\n",
    "                res['LOD'+str(round(r,2))]=tmp.LOD\n",
    "        res.index=list(res.MARKER)\n",
    "        res=res.iloc[:,1:]\n",
    "    return res\n",
    "\n",
    "def parallel_lods(haps,afreqs=None,rho=0,model = \"AD\",chrom = \"AUTOSOMAL\",penetrances = [0.01,0.9,0.9],dfreq=0.001):\n",
    "    start = time.perf_counter()\n",
    "    if afreqs is None:\n",
    "        with ProcessPoolExecutor(max_workers = 10) as executor:\n",
    "            results = executor.map(calculate_ped_lod,haps.values(),repeat(rho),repeat(model),repeat(chrom),repeat(penetrances),repeat(dfreq))\n",
    "    else:\n",
    "        with ProcessPoolExecutor(max_workers = 10) as executor:\n",
    "            results = executor.map(calculate_ped_lod,haps.values(),afreqs,repeat(rho),repeat(model),repeat(chrom),repeat(penetrances),repeat(dfreq))\n",
    "    print(time.perf_counter()-start)\n",
    "    return {k:res for k,res in zip(haps.keys(),results)}\n",
    "\n",
    "def linkage_analysis(gene_genotype_file,fam,fam_vcf,cutoff,chp=True,rho=np.arange(0,0.5,0.05),model = \"AD\",chrom = \"AUTOSOMAL\",penetrances = [0.01,0.9,0.9],dfreq=0.001):\n",
    "    '''linkage analysis function'''\n",
    "    linkage_input_file=gene_genotype_file[:-7]+'_AFcutoff'+str(cutoff)+'_linkage.input'\n",
    "    lod_file=linkage_input_file[:-6]+'.lods'\n",
    "    hlod_file=linkage_input_file[:-6]+'.hlods'\n",
    "    besthlod_file=linkage_input_file[:-6]+'.besthlod'\n",
    "    #preprocess genotypes or phased haplotypes to the format of linkage analysis\n",
    "    if os.path.isfile(linkage_input_file):\n",
    "        print('exist! jump',linkage_input_file,file=sys.stderr)\n",
    "    else:\n",
    "        print('create',linkage_input_file,file=sys.stdout)\n",
    "        with open(gene_genotype_file, 'rb') as handle:\n",
    "            genes = pickle.load(handle)\n",
    "        if chp: #making CHP markers from phased haplotypes\n",
    "            genes=update_haps_ped(genes)\n",
    "        gene_variants,gene_fam_haps = format_haps_bunch(genes,fam,fam_vcf,cutoff,chp)\n",
    "        with open(linkage_input_file,'wb') as handle:\n",
    "            pickle.dump([gene_variants,gene_fam_haps], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    #linkage analysis and write out results to .lods file\n",
    "    if os.path.isfile(lod_file):\n",
    "        print('exist! jump',lod_file,file=sys.stderr)\n",
    "    else:\n",
    "        print('create',lod_file,file=sys.stdout)\n",
    "        with open(linkage_input_file, 'rb') as handle:\n",
    "            gene_variants,gene_fam_haps = pickle.load(handle) \n",
    "        afreqs = []\n",
    "        for k in gene_fam_haps.keys():\n",
    "            variants= gene_variants[k]\n",
    "            variants=variants.freqs[variants.uniq]\n",
    "            afreqs.append(variants)\n",
    "        res = parallel_lods(gene_fam_haps,afreqs,rho,model,chrom,penetrances,dfreq) #R function for linkage analysis\n",
    "        with open(lod_file,'wb') as handle:\n",
    "            pickle.dump(res, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    #heterogeneity analysis and write out results to .hlods and .besthlods files\n",
    "    if os.path.isfile(besthlod_file):\n",
    "        print('exist! jump',besthlod_file,file=sys.stderr)\n",
    "    else:\n",
    "        print('create',besthlod_file,file=sys.stdout)\n",
    "        with open(lod_file, 'rb') as handle:\n",
    "            res = pickle.load(handle)\n",
    "        var_res=format_fam_lods(res.values(),prefix=chp)\n",
    "        var_sovs,best_sovs=[],[]\n",
    "        for var,res in var_res.items():\n",
    "            res=res.fillna(0)\n",
    "            best_sov=[var,'LOD0.5',0,0]\n",
    "            for theta in res.index:\n",
    "                try:\n",
    "                    sov = minimize_scalar(hlod_fun(list(res.loc[theta]), -1), bounds=(0,1), method='bounded', options={'xatol':1e-8})\n",
    "                    var_sov=[var,theta,sov.x,-sov.fun]\n",
    "                except:\n",
    "                    var_sov=[var,theta,0,0]\n",
    "                var_sovs.append(var_sov)\n",
    "                if best_sov[3]<var_sov[3]: \n",
    "                    best_sov=var_sov\n",
    "            best_sovs.append(best_sov)\n",
    "        var_sovs=pd.DataFrame(var_sovs)\n",
    "        best_sovs=pd.DataFrame(best_sovs)\n",
    "        with open(hlod_file,'wb') as handle:\n",
    "            pickle.dump(var_sovs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(besthlod_file,'wb') as handle:\n",
    "            pickle.dump(best_sovs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f10eb-b5c0-490d-aabf-29792fe8ef57",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a7531-7bda-4301-8b94-88f3c197a4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46859060414135456\n"
     ]
    }
   ],
   "source": [
    "with open('../data/wg20220725raretrimmed_phase/chr22test/tmp/CACHE/chr22test0_AFcutoff0.0_linkage.lods', 'rb') as handle:\n",
    "    res = pickle.load(handle)\n",
    "var_res=format_fam_lods(res.values(),prefix=True)\n",
    "start = time.perf_counter()\n",
    "var_sovs,best_sovs=[],[]\n",
    "for var,res in var_res.items():\n",
    "    res=res.fillna(0)\n",
    "    best_sov=[var,'LOD0.5',0,0]\n",
    "    for theta in res.index:\n",
    "        try:\n",
    "            sov = minimize_scalar(hlod_fun(list(res.loc[theta]), -1), bounds=(0,1), method='bounded', options={'xatol':1e-8})\n",
    "            var_sov=[var,theta,sov.x,-sov.fun]\n",
    "        except:\n",
    "            var_sov=[var,theta,0,0]\n",
    "        var_sovs.append(var_sov)\n",
    "        if best_sov[3]<var_sov[3]: \n",
    "            best_sov=var_sov\n",
    "    best_sovs.append(best_sov)\n",
    "print(time.perf_counter()-start)\n",
    "var_sovs=pd.DataFrame(var_sovs)\n",
    "best_sovs=pd.DataFrame(best_sovs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d86b9e2-aa5f-49f8-b5d1-1e76fd15f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_variant_lods(lods):\n",
    "    variants = {}\n",
    "    for lod in lods:\n",
    "        for m,l in zip(lod['MARKER'],lod['LOD']):\n",
    "            if m in variants.keys():\n",
    "                variants[m] += l\n",
    "            else:\n",
    "                variants[m] = l\n",
    "    var_lst = []\n",
    "    for var,lod in variants.items():\n",
    "        snp = var[:-3]\n",
    "        var_lst.append(snp.split(':')+[snp,lod])\n",
    "    variants=pd.DataFrame(var_lst,columns=['CHR','POS','A0','A1','SNP','LOD'])\n",
    "    variants.POS = variants.POS.astype(int)\n",
    "    variants.sort_values('POS')\n",
    "    return variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be19e4bb-4298-431b-b1fc-32708ea3e6bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### test `linkage_analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353860f8-921e-4509-891f-3ae1623796c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fam_vcf='../data/wg20220520trimed/fam17_vcf_rmfounderwithoutvcf.pickle'\n",
    "fam_path='../data/new_trim_ped_rmfounderwithoutvcf.fam'\n",
    "if os.path.isfile(fam_vcf):\n",
    "    with open(fam_vcf, 'rb') as handle:\n",
    "        fam17_vcf = pickle.load(handle)\n",
    "fam17 = pd.read_csv(fam_path,delim_whitespace=True,header=None,names=['fid','iid','fathid','mothid','sex','ad'])\n",
    "fam17.index = list(fam17.iid)\n",
    "fam17.ad[fam17.ad==-9]=0\n",
    "fam17_d = {}\n",
    "cutoff=0.0\n",
    "for i in fam17.fid.unique():\n",
    "    fam17_d[i] = fam17[fam17.fid==i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b0d6cd-8a44-4c81-af37-8b33a33fad86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exist! jump ../data/wg20220725raretrimmed/chr22test/tmp/CACHE/chr22test0_AFcutoff0.0_linkage.input\n",
      "exist! jump ../data/wg20220725raretrimmed/chr22test/tmp/CACHE/chr22test0_AFcutoff0.0_linkage.lods\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create ../data/wg20220725raretrimmed/chr22test/tmp/CACHE/chr22test0_AFcutoff0.0_linkage.besthlod\n"
     ]
    }
   ],
   "source": [
    "#genotype data\n",
    "gene_genotype_file='../data/wg20220725raretrimmed/chr22test/tmp/CACHE/chr22test0.pickle'\n",
    "linkage_analysis(gene_genotype_file,fam17_d,fam17_vcf,cutoff,chp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed863260-8f15-46d1-9472-0104e6f2aba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exist! jump ../data/wg20220725raretrimmed/chr22test/tmp/CACHE/chr22test3_AFcutoff0.0_linkage.input\n",
      "exist! jump ../data/wg20220725raretrimmed/chr22test/tmp/CACHE/chr22test3_AFcutoff0.0_linkage.lods\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create ../data/wg20220725raretrimmed/chr22test/tmp/CACHE/chr22test3_AFcutoff0.0_linkage.besthlod\n"
     ]
    }
   ],
   "source": [
    "#genotype data\n",
    "gene_genotype_file='../data/wg20220725raretrimmed/chr22test/tmp/CACHE/chr22test3.pickle'\n",
    "linkage_analysis(gene_genotype_file,fam17_d,fam17_vcf,cutoff,chp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df771c1-adfa-4b0e-a83f-7614becdfd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exist! jump ../data/wg20220725raretrimmed_phase/chr22test/tmp/CACHE/chr22test0_AFcutoff0.0_linkage.input\n",
      "exist! jump ../data/wg20220725raretrimmed_phase/chr22test/tmp/CACHE/chr22test0_AFcutoff0.0_linkage.lods\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create ../data/wg20220725raretrimmed_phase/chr22test/tmp/CACHE/chr22test0_AFcutoff0.0_linkage.besthlod\n"
     ]
    }
   ],
   "source": [
    "#haplotype data\n",
    "gene_genotype_file='../data/wg20220725raretrimmed_phase/chr22test/tmp/CACHE/chr22test0.pickle'\n",
    "linkage_analysis(gene_genotype_file,fam17_d,fam17_vcf,cutoff,chp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb231e7-5827-421a-8e15-2d9dedc12967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exist! jump ../data/wg20220725raretrimmed_phase/chr22test/tmp/CACHE/chr22test1_AFcutoff0.0_linkage.input\n",
      "exist! jump ../data/wg20220725raretrimmed_phase/chr22test/tmp/CACHE/chr22test1_AFcutoff0.0_linkage.lods\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create ../data/wg20220725raretrimmed_phase/chr22test/tmp/CACHE/chr22test1_AFcutoff0.0_linkage.besthlod\n"
     ]
    }
   ],
   "source": [
    "#haplotype data\n",
    "gene_genotype_file='../data/wg20220725raretrimmed_phase/chr22test/tmp/CACHE/chr22test1.pickle'\n",
    "linkage_analysis(gene_genotype_file,fam17_d,fam17_vcf,cutoff,chp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87983690-9a5b-4525-af50-0b01e94f78dc",
   "metadata": {},
   "source": [
    "### Functions for summarizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e38aaa-53d0-47c8-97ce-c24b340a14c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def format_fam_lods(res,cutoff=0,prefix=False):\n",
    "    new_res,variants=[],[]\n",
    "    for i in res:\n",
    "        idx=i.index\n",
    "        if prefix:\n",
    "            idx=[i.split(':',1)[0] for i in idx]\n",
    "            i.index=idx\n",
    "        else:\n",
    "            idx=[i[:-3] for i in idx] \n",
    "            i.index=idx\n",
    "        new_res.append(i)\n",
    "        variants.append(i.index)\n",
    "    variants = list(set().union(*variants))\n",
    "    var_res={}\n",
    "    for v in variants:\n",
    "        varlods = [rows2one(r.loc[v]) for r in new_res if v in r.index]\n",
    "        if len(varlods)>cutoff:\n",
    "            #v=snp:informative fam\n",
    "            v=':'.join([v,str(len(varlods))])\n",
    "            var_res[v]=pd.concat(varlods,axis=1)\n",
    "    return var_res\n",
    "\n",
    "def rows2one(x):\n",
    "    if len(x.shape)>1:\n",
    "        return x.max(axis=0)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def get_lods_batch(path,fams=None,phase=False):\n",
    "    with open(path, 'rb') as handle:\n",
    "        res=pickle.load(handle)\n",
    "        if fams is not None:\n",
    "            try:\n",
    "                res=[r for k,r in res.items() if k in fams]\n",
    "            except:\n",
    "                with open(path[:-4]+'input', 'rb') as handle:\n",
    "                    gene_variants,gene_fam_haps=pickle.load(handle)\n",
    "                res={k:r for k,r in zip(gene_fam_haps.keys(),res)}\n",
    "                res=[r for k,r in res.items() if k in fams]\n",
    "        else:\n",
    "            if type(res) is dict:\n",
    "                res=res.values()\n",
    "    res_d=format_fam_lods(res,prefix=phase)\n",
    "    #sum lods among families\n",
    "    lods=pd.concat([x.sum(axis=1) for x in res_d.values()],axis=1).T\n",
    "    lods.index=list(res_d.keys())\n",
    "    return lods\n",
    "\n",
    "def get_lods_chrom(prefix,fams=None,phase=False):\n",
    "    path_ress=glob.glob(prefix)\n",
    "    ress = []\n",
    "    for x in path_ress:\n",
    "        try:\n",
    "            res=get_lods_batch(x,fams,phase)\n",
    "        except:\n",
    "            continue\n",
    "        if len(res)==0:\n",
    "            continue\n",
    "        ress.append(res)\n",
    "    ress=pd.concat(ress)\n",
    "    return ress[~ress.index.duplicated(keep=False)]\n",
    "\n",
    "def get_hlod_chrom(prefix):\n",
    "    path_ress=glob.glob(prefix)\n",
    "    ress = []\n",
    "    for x in path_ress:\n",
    "        try:\n",
    "            with open(x,'rb') as handle:\n",
    "                res=pickle.load(handle)\n",
    "        except:\n",
    "            continue\n",
    "        if len(res)==0:\n",
    "            continue\n",
    "        ress.append(res)\n",
    "    ress=pd.concat(ress)\n",
    "    ress.columns=['name','theta','alpha','hlod']\n",
    "    ress.index=list(ress.name)\n",
    "    return ress[~ress.index.duplicated(keep=False)]\n",
    "\n",
    "def summarize_lods(input_lod,output_prefix,regions,fams=None,phase=False):\n",
    "    '''two output files:one is lod scores from rho 0 to 0.5. another is lod at rho=0 and max lod score combined with chr, pos and name'''\n",
    "    lods_chr = get_lods_chrom(input_lod,fams,phase)\n",
    "    hlod_chr = get_hlod_chrom(input_lod[:-4]+'besthlod')\n",
    "    lods_chr.sort_index().to_csv(output_prefix+'_lods.csv',header=True,index=True)\n",
    "\n",
    "    # get the max lod for each gene\n",
    "    info_fam=[int(i.rsplit(':',1)[1]) for i in lods_chr.index]\n",
    "    lods_chr.index=[i.rsplit(':',1)[0] for i in lods_chr.index]\n",
    "    hlod_chr.index=[i.rsplit(':',1)[0] for i in hlod_chr.index]\n",
    "    if phase:\n",
    "        genes=pd.DataFrame(regions).iloc[:,:4]\n",
    "        genes.columns=['chrom','start','end','name']\n",
    "        genes.index=list(genes.name)\n",
    "        genes=genes[genes.index.isin(lods_chr.index)]\n",
    "    else:\n",
    "        genes=pd.DataFrame([i.split(':') for i in lods_chr.index])\n",
    "        genes.columns=['chrom','pos','a0','a1']\n",
    "        genes.index=list(lods_chr.index)\n",
    "        \n",
    "    lods_chr=lods_chr.loc[genes.index,:]\n",
    "    hlod_chr=hlod_chr.loc[genes.index,:]\n",
    "    genes['InfoFam']=info_fam\n",
    "    genes['LOD0']=list(lods_chr['LOD0.0'])\n",
    "    genes['LODmax']=list(lods_chr.max(axis=1))            \n",
    "    genes.loc[genes.LODmax<0,'LODmax']=0\n",
    "    pd.concat([genes,hlod_chr.loc[:,['theta','alpha','hlod']]],axis=1).sort_index().to_csv(output_prefix+'_lod_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0f578-dacf-4793-ab8a-8b4c650ceb60",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e6c49-288f-4d75-ba79-e2911545b3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/2742267.1.high_mem.q/ipykernel_32628/1320168421.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genes.LODmax[genes.LODmax<0]=0\n"
     ]
    }
   ],
   "source": [
    "summarize_lods('../data/wg20220725raretrimmed_phase/chr22test/tmp/CACHE/*_linkage.lods','../data/wg20220725raretrimmed_phase/chr22test',regions,phase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9286e38-c315-4cdc-a5fe-dfcafc11fc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/2742267.1.high_mem.q/ipykernel_32628/1320168421.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genes.LODmax[genes.LODmax<0]=0\n"
     ]
    }
   ],
   "source": [
    "summarize_lods('../data/wg20220725raretrimmed/chr22test/tmp/CACHE/*_linkage.lods','../data/wg20220725raretrimmed/chr22test',regions,phase=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
