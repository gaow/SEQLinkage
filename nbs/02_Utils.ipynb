{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils module\n",
    "\n",
    "> util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "VERSION = '1.1.0'\n",
    "import sys, os, subprocess, shutil, glob, shlex, re, hashlib, tempfile\n",
    "try:\n",
    "    from cStringIO import StringIO ## for Python 2\n",
    "    import urlparse\n",
    "except ImportError:\n",
    "    from io import StringIO ## for Python 3\n",
    "    from urllib import parse as urlparse\n",
    "from contextlib import contextmanager\n",
    "from multiprocessing import Pool, Process, Queue, Lock, Value, cpu_count\n",
    "import itertools\n",
    "from collections import OrderedDict, defaultdict, Counter\n",
    "from shutil import rmtree as remove_tree\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# from distutils.dir_util import mkpath\n",
    "def mkpath(directory):\n",
    "    '''Have to use system mkdir here because python2.7's mkpath is currently faulty!'''\n",
    "    os.system('mkdir -p {}'.format(directory))\n",
    "\n",
    "###\n",
    "# Global variables\n",
    "###\n",
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.__width_cache = 1\n",
    "        # About the program\n",
    "        self.proj = \"SEQLinkage\"\n",
    "        self.prog = 'seqlink'\n",
    "        self.version = VERSION\n",
    "        # Input & output options\n",
    "        self.outdir = None\n",
    "        self.output = None\n",
    "        self.cache_dir = None\n",
    "        self.tmp_dir = None\n",
    "        self.tmp_cache = None\n",
    "        self.tmp_log = None\n",
    "        # Runtime support\n",
    "        self.resource_dir = os.path.expanduser('~/.{}'.format(self.proj))\n",
    "        self.resource_bin = os.path.join(self.resource_dir, 'bin')\n",
    "        self.path = {'PATH':\"{}:{}\".format(self.resource_bin, os.environ[\"PATH\"])}\n",
    "        self.debug = False\n",
    "        self.quiet = False\n",
    "        # File contents\n",
    "        self.build = 'hg38'\n",
    "        self.delimiter = \" \"\n",
    "        self.ped_missing = ['0', '-9'] + ['none', 'null', 'na', 'nan', '.']\n",
    "        self.trait = 'binary'\n",
    "        self.prephased = False\n",
    "        # Multiprocessing counters\n",
    "        self.batch = 50\n",
    "        self.lock = Lock()\n",
    "        self.total_counter = Value('i',0)\n",
    "        self.success_counter = Value('i',0)\n",
    "        self.null_counter = Value('i',0)\n",
    "        self.trivial_counter = Value('i',0)\n",
    "        self.chperror_counter = Value('i',0)\n",
    "        self.variants_counter = Value('i',0)\n",
    "        self.triallelic_counter = Value('i',0)\n",
    "        self.commonvar_counter = Value('i',0)\n",
    "        self.mendelerror_counter = Value('i',0)\n",
    "        self.recomb_counter = Value('i',0)\n",
    "        self.format_counter = Value('i',0)\n",
    "        self.run_counter = Value('i',0)\n",
    "        self.skipped_counter = Value('i',0)\n",
    "        self.makeped_counter = Value('i',0)\n",
    "        self.pedcheck_counter = Value('i',0)\n",
    "        self.unknown_counter = Value('i',0)\n",
    "        self.mlink_counter = Value('i',0)\n",
    "        self.dtest = {}  #test line\n",
    "        self.jobs = None\n",
    "        \n",
    "    def setoutput(self,outdir):\n",
    "        # Input & output options\n",
    "        if outdir:\n",
    "            self.outdir = outdir\n",
    "            self.output = os.path.split(outdir)[-1]\n",
    "        else:\n",
    "            self.outdir = 'LINKAGE'\n",
    "            self.output = 'LINKAGE'\n",
    "        mkpath(self.outdir)\n",
    "        self.cache_dir = os.path.join(self.outdir, 'cache')\n",
    "        self.tmp_dir = self.__mktmpdir(os.path.join(self.outdir, 'tmp'))\n",
    "        self.tmp_cache = os.path.join(self.tmp_dir, 'CACHE')\n",
    "        self.tmp_log = os.path.join(self.tmp_dir, \"clog.\" + self.output + \".STDOUT\")\n",
    "\n",
    "    def __mktmpdir(self, where = None):\n",
    "        class LockedTempDir(str):\n",
    "            def __init__(self, path):\n",
    "                self = path\n",
    "                open(os.path.join(self, '.lock'), 'a').close()\n",
    "\n",
    "            def __del__(self):\n",
    "                try:\n",
    "                    os.remove(os.path.join(self, '.lock'))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        if where in [None, 'None', '']:\n",
    "            where = tempfile.gettempdir()\n",
    "        else:\n",
    "            where = os.path.expanduser(where)\n",
    "            mkpath(where)\n",
    "        if os.path.isdir(where) and ((not os.access(where, os.R_OK)) or (not os.access(where, os.W_OK))):\n",
    "            self.error('Cannot set temporary directory to directory {} because '.format(where) + \\\n",
    "                       'it is not readable or writable.', exit = True)\n",
    "        pattern = re.compile(r'{}_tmp_*(.*)'.format(self.proj))\n",
    "        for fn in os.listdir(where):\n",
    "            if pattern.match(fn) and not os.path.isfile(os.path.join(where, fn, '.lock')):\n",
    "                try:\n",
    "                    remove_tree(os.path.join(where, fn))\n",
    "                except:\n",
    "                    pass\n",
    "        tmp = LockedTempDir(tempfile.mkdtemp(prefix='{}_tmp_'.format(self.proj), dir = where))\n",
    "        mkpath(os.path.join(tmp, 'CACHE'))\n",
    "        return tmp\n",
    "\n",
    "    def ResetTempdir(self, path = None):\n",
    "        self.tmp_dir = self.__mktmpdir(path)\n",
    "        self.tmp_cache = os.path.join(self.tmp_dir, 'CACHE')\n",
    "        self.tmp_log = os.path.join(self.tmp_dir, \"clog.\" + self.output)\n",
    "\n",
    "    def error(self, msg = None, show_help = False, exit = False):\n",
    "        if msg is None:\n",
    "            sys.stderr.write('\\n')\n",
    "            return\n",
    "        if type(msg) is list:\n",
    "            msg = ' '.join(map(str, msg))\n",
    "        else:\n",
    "            msg = str(msg)\n",
    "        start = '\\n' if msg.startswith('\\n') else ''\n",
    "        end = '\\n' if msg.endswith('\\n') else ''\n",
    "        msg = msg.strip()\n",
    "        sys.stderr.write(start + \"\\033[1;40;33mERROR: {}\\033[0m\\n\".format(msg) + end)\n",
    "        if show_help:\n",
    "            self.log(\"Type '{} -h' for help message\".format(env.prog))\n",
    "            sys.exit()\n",
    "        if exit:\n",
    "            sys.exit()\n",
    "\n",
    "    def log(self, msg = None, flush=False):\n",
    "        if self.debug or self.quiet:\n",
    "            return\n",
    "        if msg is None:\n",
    "            sys.stderr.write('\\n')\n",
    "            return\n",
    "        if type(msg) is list:\n",
    "            msg = ' '.join(map(str, msg))\n",
    "        else:\n",
    "            msg = str(msg)\n",
    "        start = \"{0:{width}}\".format('\\r', width = self.__width_cache + 10) + \"\\r\" if flush else ''\n",
    "        end = '' if flush else '\\n'\n",
    "        start = '\\n' + start if msg.startswith('\\n') else start\n",
    "        end = end + '\\n' if msg.endswith('\\n') else end\n",
    "        msg = msg.strip()\n",
    "        sys.stderr.write(start + \"\\033[1;40;32mMESSAGE: {}\\033[0m\".format(msg) + end)\n",
    "        self.__width_cache = len(msg)\n",
    "global env\n",
    "env = Environment()\n",
    "###\n",
    "# Utility function / classes\n",
    "###\n",
    "\n",
    "class StdoutCapturer(list):\n",
    "    def __enter__(self):\n",
    "        self._stdout = sys.stdout\n",
    "        sys.stdout = self._stringio = StringIO()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.extend(self._stringio.getvalue().splitlines())\n",
    "        sys.stdout = self._stdout\n",
    "\n",
    "@contextmanager\n",
    "def stdoutRedirect(to=os.devnull):\n",
    "    '''\n",
    "    import os\n",
    "\n",
    "    with stdoutRedirect(to=filename):\n",
    "        print(\"from Python\")\n",
    "        os.system(\"echo non-Python applications are also supported\")\n",
    "    '''\n",
    "    fd = sys.stdout.fileno()\n",
    "\n",
    "    ##### assert that Python and C stdio write using the same file descriptor\n",
    "    ####assert libc.fileno(ctypes.c_void_p.in_dll(libc, \"stdout\")) == fd == 1\n",
    "\n",
    "    def _redirect_stdout(to):\n",
    "        sys.stdout.close() # + implicit flush()\n",
    "        os.dup2(to.fileno(), fd) # fd writes to 'to' file\n",
    "        sys.stdout = os.fdopen(fd, 'w') # Python writes to fd\n",
    "\n",
    "    with os.fdopen(os.dup(fd), 'w') as old_stdout:\n",
    "        with open(to, 'a') as file:\n",
    "            _redirect_stdout(to=file)\n",
    "        try:\n",
    "            yield # allow code to be run with the redirected stdout\n",
    "        finally:\n",
    "            _redirect_stdout(to=old_stdout) # restore stdout.\n",
    "                                            # buffering and flags such as\n",
    "                                            # CLOEXEC may be different\n",
    "\n",
    "#http://stackoverflow.com/a/13197763, by Brian M. Hunt\n",
    "class cd:\n",
    "    \"\"\"Context manager for changing the current working directory\"\"\"\n",
    "    def __init__(self, newPath):\n",
    "        self.newPath = newPath\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.savedPath = os.getcwd()\n",
    "        os.chdir(self.newPath)\n",
    "\n",
    "    def __exit__(self, etype, value, traceback):\n",
    "        os.chdir(self.savedPath)\n",
    "\n",
    "def runCommand(cmd, instream = None, msg = '', upon_succ = None, show_stderr = False, return_zero = True):\n",
    "    if isinstance(cmd, str):\n",
    "        cmd = shlex.split(cmd)\n",
    "    popen_env = os.environ.copy()\n",
    "    popen_env.update(env.path)\n",
    "    try:\n",
    "        tc = subprocess.Popen(cmd, stdin = subprocess.PIPE,\n",
    "                              stdout = subprocess.PIPE, stderr = subprocess.PIPE,\n",
    "                              env=popen_env)\n",
    "        if instream:\n",
    "            if sys.version_info.major == 3:\n",
    "                instream = instream.encode(sys.getdefaultencoding())\n",
    "            out, error = tc.communicate(instream)\n",
    "        else:\n",
    "            out, error = tc.communicate()\n",
    "        if sys.version_info.major == 3:\n",
    "            out = out.decode(sys.getdefaultencoding())\n",
    "            error = error.decode(sys.getdefaultencoding())\n",
    "        if return_zero:\n",
    "            if tc.returncode < 0:\n",
    "                raise ValueError (\"Command '{0}' was terminated by signal {1}\".format(cmd, -tc.returncode))\n",
    "            elif tc.returncode > 0:\n",
    "                raise ValueError (\"{0}\".format(error))\n",
    "        if error.strip() and show_stderr:\n",
    "            env.log(error)\n",
    "    except OSError as e:\n",
    "        raise OSError (\"Execution of command '{0}' failed: {1}\".format(cmd, e))\n",
    "    # everything is OK\n",
    "    if upon_succ:\n",
    "        # call the function (upon_succ) using others as parameters.\n",
    "        upon_succ[0](*(upon_succ[1:]))\n",
    "    return out, error\n",
    "\n",
    "class CMDWorker(Process):\n",
    "    def __init__(self, queue):\n",
    "        Process.__init__(self)\n",
    "        self.queue = queue\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            try:\n",
    "                cmd = self.queue.get()\n",
    "                if cmd is None:\n",
    "                    break\n",
    "                else:\n",
    "                    runCommand(cmd)\n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "\n",
    "def runCommands(cmds, ncpu):\n",
    "    try:\n",
    "        jobs = []\n",
    "        queue = Queue()\n",
    "        for i in cmds:\n",
    "            queue.put(i)\n",
    "        for i in range(ncpu):\n",
    "            p = CMDWorker(queue)\n",
    "            p.start()\n",
    "            jobs.append(p)\n",
    "            queue.put(None)\n",
    "        for j in jobs:\n",
    "            j.join()\n",
    "    except KeyboardInterrupt:\n",
    "        raise ValueError('Commands terminated!')\n",
    "\n",
    "#utils that allow lambda function in mutilprocessing map\n",
    "#http://stackoverflow.com/a/16071616 by klaus-se\n",
    "def parmap(f, X, nprocs = cpu_count()):\n",
    "    def spawn(f):\n",
    "        def fun(q_in,q_out):\n",
    "            while True:\n",
    "                i,x = q_in.get()\n",
    "                if i is None:\n",
    "                    break\n",
    "                q_out.put((i,f(x)))\n",
    "        return fun\n",
    "    #\n",
    "    q_in   = Queue(1)\n",
    "    q_out  = Queue()\n",
    "    proc = [Process(target=spawn(f),args=(q_in,q_out)) for _ in range(nprocs)]\n",
    "    for p in proc:\n",
    "        p.daemon = True\n",
    "        p.start()\n",
    "    sent = [q_in.put((i,x)) for i,x in enumerate(X)]\n",
    "    [q_in.put((None,None)) for _ in range(nprocs)]\n",
    "    res = [q_out.get() for _ in range(len(sent))]\n",
    "    [p.join() for p in proc]\n",
    "    return [x for i,x in sorted(res)]\n",
    "\n",
    "def downloadURL(URL, dest_dir, quiet = True, mode = None, force = False):\n",
    "    if not os.path.isdir(dest_dir):\n",
    "        mkpath(dest_dir)\n",
    "    filename = os.path.split(urlparse.urlsplit(URL).path)[-1]\n",
    "    dest = os.path.join(dest_dir, filename)\n",
    "    if os.path.isfile(dest):\n",
    "        if force:\n",
    "            os.remove(dest)\n",
    "        else:\n",
    "            return\n",
    "    # use wget\n",
    "    try:\n",
    "        # for some strange reason, passing wget without shell=True can fail silently.\n",
    "        p = subprocess.Popen('wget {} -O {} {}'.format('-q' if quiet else '', dest, URL), shell=True)\n",
    "        ret = p.wait()\n",
    "        if ret == 0 and os.path.isfile(dest):\n",
    "            if mode is not None:\n",
    "                subprocess.Popen('chmod {} {}'.format(mode, dest), shell=True)\n",
    "            return dest\n",
    "        else:\n",
    "            try:\n",
    "                os.remove(dest)\n",
    "            except:\n",
    "                pass\n",
    "            raise RuntimeError('Failed to download {} using wget'.format(URL))\n",
    "    except (RuntimeError, ValueError, OSError):\n",
    "        # no wget command\n",
    "        env.error('Failed to download {}'.format(filename))\n",
    "\n",
    "def calculateFileMD5(filename):\n",
    "    md5 = hashlib.md5()\n",
    "    # limit the calculation to the first 1G of the file content\n",
    "    block_size = 2**20  # buffer of 1M\n",
    "    filesize = os.path.getsize(filename)\n",
    "    try:\n",
    "        if filesize < 2**26:\n",
    "            # for file less than 1G, use all its content\n",
    "            with open(filename, 'rb') as f:\n",
    "                while True:\n",
    "                    data = f.read(block_size)\n",
    "                    if not data:\n",
    "                        break\n",
    "                    md5.update(data)\n",
    "        else:\n",
    "            count = 64\n",
    "            # otherwise, use the first and last 500M\n",
    "            with open(filename, 'rb') as f:\n",
    "                while True:\n",
    "                    data = f.read(block_size)\n",
    "                    count -= 1\n",
    "                    if count == 32:\n",
    "                        f.seek(-2**25, 2)\n",
    "                    if not data or count == 0:\n",
    "                        break\n",
    "                    md5.update(data)\n",
    "    except IOError as e:\n",
    "        sys.exit('Failed to read {}: {}'.format(filename, e))\n",
    "    return md5.hexdigest()\n",
    "\n",
    "def zipdir(path, zipfile, arcroot = '/'):\n",
    "    path = os.path.normpath(path)\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            zipfile.write(os.path.join(root, f),\n",
    "                          arcname = os.path.join(arcroot, root[len(path) + 1:], f))\n",
    "\n",
    "def removeFiles(dest, exclude = [], hidden = False):\n",
    "    if os.path.isdir(dest):\n",
    "        for item in os.listdir(dest):\n",
    "            if item.startswith('.') and hidden == False:\n",
    "                continue\n",
    "            if os.path.splitext(item)[1] not in exclude:\n",
    "                try:\n",
    "                    os.remove(os.path.join(dest,item))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "def removeEmptyDir(directory):\n",
    "    try:\n",
    "        if not os.listdir(directory):\n",
    "            os.rmdir(directory)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def copyFiles(pattern, dist, ignore_hidden = True):\n",
    "    mkpath(dist)\n",
    "    for fl in glob.glob(pattern):\n",
    "        if os.path.isfile(fl):\n",
    "            shutil.copy(fl, dist)\n",
    "\n",
    "def downloadResources(fromto):\n",
    "    for idx, item in enumerate(fromto):\n",
    "        env.log('Checking local resources {0}/{1} ...'.format(idx + 1, len(fromto)), flush = True)\n",
    "        downloadURL(item[0], item[1], mode = 777)\n",
    "    env.log()\n",
    "    return True\n",
    "\n",
    "def getColumn(fn, num, delim = None, exclude = None):\n",
    "    if num > 0:\n",
    "        num = num - 1\n",
    "    with open(fn) as inf:\n",
    "        output = []\n",
    "        for line in inf:\n",
    "            parts = line.split(delim) if delim is not None else line.split()\n",
    "            if len(parts) > num and parts[num] != exclude:\n",
    "                output.append(parts[num])\n",
    "    return output\n",
    "\n",
    "def wordCount(filename):\n",
    "    \"\"\"Returns a word/count dict for this filename.\"\"\"\n",
    "    word_count = {}\n",
    "    with open(filename, 'r') as input_file:\n",
    "        for line in input_file:\n",
    "            words = line.split()\n",
    "            for word in words:\n",
    "                word = word.lower()\n",
    "                if not word in word_count:\n",
    "                    word_count[word] = 1\n",
    "                else:\n",
    "                    word_count[word] += 1\n",
    "    return word_count\n",
    "\n",
    "def fileLinesCount(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "def connected_components(lists):\n",
    "    neighbors = defaultdict(set)\n",
    "    seen = set()\n",
    "    for each in lists:\n",
    "        for item in each:\n",
    "            neighbors[item].update(each)\n",
    "    def component(node, neighbors=neighbors, seen=seen, see=seen.add):\n",
    "        nodes = set([node])\n",
    "        next_node = nodes.pop\n",
    "        while nodes:\n",
    "            node = next_node()\n",
    "            see(node)\n",
    "            nodes |= neighbors[node] - seen\n",
    "            yield node\n",
    "    for node in neighbors:\n",
    "        if node not in seen:\n",
    "            yield sorted(component(node))\n",
    "\n",
    "def listit(t):\n",
    "    return list(map(listit, t)) if isinstance(t, (list, tuple)) else t\n",
    "\n",
    "###\n",
    "# Supporting functions / classes for Core.py\n",
    "###\n",
    "\n",
    "def parseVCFline(line, exclude = []):\n",
    "    if len(line) == 0:\n",
    "        return None\n",
    "    line = line.split('\\t')\n",
    "    # Skip tri-allelic variant\n",
    "    if \",\" in line[4]:\n",
    "        with env.lock:\n",
    "            env.triallelic_counter.value += 1\n",
    "        return None\n",
    "    gs = []\n",
    "    for idx in range(len(line)):\n",
    "        if idx < 9 or idx in exclude:\n",
    "            continue\n",
    "        else:\n",
    "            # Remove separater\n",
    "            g = re.sub('\\/|\\|','',line[idx].split(\":\")[0])\n",
    "            if g == '.' or g == '..':\n",
    "                gs.append(\"00\")\n",
    "            else:\n",
    "                gs.append(g.replace('1','2').replace('0','1'))\n",
    "    return (line[0], line[1], line[3], line[4], line[2]), gs\n",
    "\n",
    "def indexVCF(vcf, verbose = True):\n",
    "    if not vcf.endswith(\".gz\"):\n",
    "        if os.path.exists(vcf + \".gz\"):\n",
    "            if verbose:\n",
    "                env.error(\"Cannot compress [{0}] because [{0}.gz] exists!\".format(vcf), exit = True)\n",
    "            else:\n",
    "                sys.exit()\n",
    "        if verbose:\n",
    "            env.log(\"Compressing file [{0}] to [{0}.gz] ...\".format(vcf))\n",
    "        runCommand('bgzip {0}'.format(vcf))\n",
    "        vcf += \".gz\"\n",
    "    if not os.path.isfile(vcf + '.tbi') or os.path.getmtime(vcf) > os.path.getmtime(vcf + '.tbi'):\n",
    "        if verbose:\n",
    "            env.log(\"Generating index file for [{}] ...\".format(vcf))\n",
    "        runCommand('tabix -p vcf -f {}'.format(vcf))\n",
    "    return vcf\n",
    "\n",
    "def extractSamplenames(vcf):\n",
    "    samples = runCommand('tabix -H {}'.format(vcf))[0].strip().split('\\n')[-1].split('\\t')[9:]\n",
    "    if not samples:\n",
    "        env.error(\"Fail to extract samples from [{}]\".format(vcf), exit = True)\n",
    "    return samples\n",
    "\n",
    "def checkVCFBundle(vcf):\n",
    "    '''VCF bundle should have a .gz file and a tabix file'''\n",
    "    if not vcf.endswith(\".gz\"):\n",
    "        env.error(\"Input VCF file has to be bgzipped and indexed (http://samtools.sourceforge.net/tabix.shtml).\",\n",
    "                  exit = True)\n",
    "    if not os.path.isfile(vcf + '.tbi'):\n",
    "        env.error(\"Index file [{}] not found.\".format(vcf + '.tbi'), exit = True)\n",
    "    return True\n",
    "\n",
    "def rewriteFamfile(tfam, samples, keys):\n",
    "    with open(tfam, 'w') as f:\n",
    "        f.write('\\n'.join(['\\t'.join(samples[k]) for k in keys]))\n",
    "        f.write('\\n')\n",
    "\n",
    "def checkSamples(samp1, samp2):\n",
    "    '''check if two sample lists agree\n",
    "    1. samples in FAM but not in VCF --> ERROR\n",
    "    2. samples in VCF but not in FAM --> give a message'''\n",
    "    a_not_b = list(set(samp1).difference(set(samp2)))\n",
    "    b_not_a = list(set(samp2).difference(set(samp1)))\n",
    "    if b_not_a:\n",
    "        env.log('{:,d} samples found in FAM file but not in VCF file:\\n{}'.\\\n",
    "                           format(len(b_not_a), ', '.join(b_not_a)))\n",
    "    if a_not_b:\n",
    "        env.log('{:,d} samples in VCF file will be ignored due to absence in FAM file'.format(len(a_not_b)))\n",
    "    return a_not_b, b_not_a\n",
    "\n",
    "class NoCache:\n",
    "    def setID(self, ID):\n",
    "        pass\n",
    "    def check(self):\n",
    "        return True\n",
    "    def load(self, target_dir = None, names = None):\n",
    "        pass\n",
    "    def write(self, source_dir = None, arcroot = '/', pres = [], exts=[],\n",
    "              files = [], mode = 'w'):\n",
    "        pass\n",
    "    def clear(self, pres = [], exts = []):\n",
    "        pass\n",
    "\n",
    "class Cache:\n",
    "    def __init__(self, cache_dir, cache_name, params):\n",
    "        self.cache_dir = cache_dir\n",
    "        self.cache_name = os.path.join(cache_dir, cache_name + '.cache')\n",
    "        self.cache_info = os.path.join(cache_dir, '.info.' + cache_name)\n",
    "        self.param_info = os.path.join(cache_dir, '.conf.' + cache_name)\n",
    "        mkpath(cache_dir)\n",
    "        self.id = '.'\n",
    "        self.params = params\n",
    "        self.infofiles = [params['vcf'], params['tfam'], params['blueprint']] if params['blueprint'] else [params['vcf'], params['tfam']]\n",
    "        self.infofiles.append(self.cache_name)\n",
    "        self.pchecklist = {'.vcf': ['bin', 'single_markers'],\n",
    "                           '.mega2':None, '.merlin':None,'.plink':None,\n",
    "                           '.linkage': ['prevalence', 'inherit_mode', 'wild_pen',\n",
    "                                        'muta_pen', 'theta_max', 'theta_inc'],\n",
    "                           '.analysis': ['prevalence', 'inherit_mode', 'wild_pen',\n",
    "                                        'muta_pen', 'theta_max', 'theta_inc']}\n",
    "\n",
    "    def setID(self, ID):\n",
    "        self.id = \".\" + str(ID)\n",
    "\n",
    "    def check(self,path=None):\n",
    "        if not os.path.isfile(self.cache_info) or not os.path.isfile(self.param_info + self.id):\n",
    "            return False\n",
    "        with open(self.cache_info, 'r') as f:\n",
    "            lines = [item.strip().split() for item in f.readlines()]\n",
    "        for line in lines:\n",
    "            if not os.path.isfile(line[0]) or line[1] != calculateFileMD5(line[0]):\n",
    "                return False\n",
    "        params = {}\n",
    "        with open(self.param_info + self.id, 'r') as f:\n",
    "            lines = [item.strip().split() for item in f.readlines()]\n",
    "        for line in lines:\n",
    "            params[line[0]] = line[1]\n",
    "        if self.pchecklist[self.id]:\n",
    "            for item in self.pchecklist[self.id]:\n",
    "                if params[item] != str(self.params[item]):\n",
    "                    return False\n",
    "        if path:\n",
    "            return os.path.isdir(path)\n",
    "        return True\n",
    "\n",
    "    def load(self, target_dir = None, names = None):\n",
    "        if target_dir is None:\n",
    "            target_dir = self.cache_dir\n",
    "        with ZipFile(self.cache_name, allowZip64 = True) as f:\n",
    "            if names is None:\n",
    "                mkpath(target_dir)\n",
    "                f.extractall(target_dir)\n",
    "            else:\n",
    "                for item in f.namelist():\n",
    "                    mkpath(target_dir)\n",
    "                    if any([item.startswith(x) for x in names]):\n",
    "                        f.extract(item, target_dir)\n",
    "\n",
    "    def write(self, source_dir = None, arcroot = '/', pres = [], exts = [],\n",
    "              files = [], mode = 'w'):\n",
    "        '''Add files to cache'''\n",
    "        if source_dir is None:\n",
    "            source_dir = self.cache_dir\n",
    "        with ZipFile(self.cache_name, mode, allowZip64 = True) as f:\n",
    "            if source_dir != self.cache_dir:\n",
    "                zipdir(source_dir, f, arcroot = arcroot)\n",
    "            else:\n",
    "                for item in os.listdir(source_dir):\n",
    "                    if ((any([item.endswith(x) for x in exts]) or len(exts) == 0) \\\n",
    "                        and (any([item.startswith(x) for x in pres]) or len(pres) == 0)) \\\n",
    "                        or item in files:\n",
    "                        f.write(os.path.join(source_dir, item), arcname=os.path.join(arcroot, item))\n",
    "        signatures = ['{}\\t{}'.format(x, calculateFileMD5(x)) for x in self.infofiles if os.path.isfile(x)]\n",
    "        with open(self.cache_info, 'w') as f:\n",
    "            f.write('\\n'.join(signatures))\n",
    "        if self.pchecklist[self.id]:\n",
    "            with open(self.param_info + self.id, 'w') as f:\n",
    "                f.write('\\n'.join([\"{}\\t{}\".format(item, self.params[item]) for item in self.pchecklist[self.id]]))\n",
    "\n",
    "    def clear(self, pres = [], exts = []):\n",
    "        for fl in glob.glob(self.cache_info + \"*\") + [self.cache_name]:\n",
    "            try:\n",
    "                os.remove(fl)\n",
    "            except:\n",
    "                pass\n",
    "        #\n",
    "        for pre, ext in itertools.product(pres, exts):\n",
    "            for fl in glob.glob(os.path.join(self.cache_dir, pre) +  \"*\" + ext):\n",
    "                try:\n",
    "                    os.remove(fl)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "class PseudoAutoRegion:\n",
    "    def __init__(self, chrom, build):\n",
    "        if build == ['hg18', 'build36'] and chrom.lower() in ['x', '23']:\n",
    "            self.check = self.checkChrX_hg18\n",
    "        elif build in ['hg18', 'build36'] and chrom.lower() in ['y', '24']:\n",
    "            self.check = self.checkChrY_hg18\n",
    "        elif build in ['hg19', 'build37'] and chrom.lower() in ['x', '23']:\n",
    "            self.check = self.checkChrX_hg19\n",
    "        elif build in ['hg19', 'build37'] and chrom.lower() in ['y', '24']:\n",
    "            self.check = self.checkChrY_hg19\n",
    "        elif build in ['hg38', 'build38'] and chrom.lower() in ['x', '23']:\n",
    "            self.check = self.checkChrX_hg38\n",
    "        elif build in ['hg38', 'build38'] and chrom.lower() in ['y', '24']:\n",
    "            self.check = self.checkChrY_hg38\n",
    "        else:\n",
    "            self.check = self.notWithinRegion\n",
    "\n",
    "    def checkChrX_hg18(self, pos):\n",
    "        return (pos >= 1 and pos <= 2709520) or \\\n",
    "            (pos >= 154584238 and pos <= 154913754)\n",
    "\n",
    "    def checkChrY_hg18(self, pos):\n",
    "        return (pos >= 1 and pos <= 2709520) or \\\n",
    "            (pos >= 57443438 and pos <= 57772954)\n",
    "\n",
    "    def checkChrX_hg19(self, pos):\n",
    "        return (pos >= 60001 and pos <= 2699520) or \\\n",
    "            (pos >= 154931044 and pos <= 155270560)\n",
    "\n",
    "    def checkChrY_hg19(self, pos):\n",
    "        return (pos >= 10001 and pos <= 2649520) or \\\n",
    "            (pos >= 59034050 and pos <= 59373566)\n",
    "\n",
    "    def checkChrX_hg38(self, pos):\n",
    "        # https://useast.ensembl.org/info/genome/genebuild/human_PARS.html\n",
    "        return (pos >= 10001 and pos <= 2781479) or \\\n",
    "            (pos >= 155701383 and pos <= 156030895)\n",
    "\n",
    "    def checkChrY_hg38(self, pos):\n",
    "        return (pos >= 10001 and pos <= 2781479) or \\\n",
    "            (pos >= 56887903 and pos <= 57217415)\n",
    "\n",
    "    def notWithinRegion(self, pos):\n",
    "        return False\n",
    "\n",
    "\n",
    "class TFAMParser:\n",
    "    def __init__(self, tfam = None):\n",
    "        self.families, self.samples, self.graph = self.__parse(tfam)\n",
    "        self.families_sorted = OrderedDict([(k,[]) for k in self.families])\n",
    "\n",
    "    def is_founder(self, sid):\n",
    "        return self.samples[sid][2] == \"0\" and self.samples[sid][3] == \"0\"\n",
    "\n",
    "    def get_parents(self, sid):\n",
    "        return self.samples[sid][2], self.samples[sid][3]\n",
    "\n",
    "    def add_member(self, info):\n",
    "        '''member is one line of FAM file, [fid, sid, pid, mid, sex, pheno]'''\n",
    "        self.samples[info[1]] = info\n",
    "        self.families_sorted[info[0]] = []\n",
    "        if info[0] not in self.families:\n",
    "            self.families[info[0]] = [info[1]]\n",
    "        else:\n",
    "            if info[1] not in self.families[info[0]]:\n",
    "                self.families[info[0]].append(info[1])\n",
    "        self.__update_graph(self.graph, info)\n",
    "\n",
    "    def get_member_idx(self, sid):\n",
    "        '''integer index, reflecting the order of the sample collected'''\n",
    "        return self.samples.keys().index(sid)\n",
    "\n",
    "    def get_members(self):\n",
    "        return self.samples.keys()\n",
    "\n",
    "    def print_member(self, sid):\n",
    "        return ' '.join(self.samples[sid][1:])\n",
    "\n",
    "    def sort_family(self, famid):\n",
    "        '''sort samples in family such that founders precede non-founders'''\n",
    "        if not self.families_sorted[famid]:\n",
    "            self.families_sorted[famid] = self.__kahn_sort(famid)\n",
    "        assert sorted(self.families_sorted[famid]) == sorted(self.families[famid])\n",
    "        return self.families_sorted[famid]\n",
    "\n",
    "    def __kahn_sort(self, famid):\n",
    "        '''algorithm first described by Kahn (1962); implemented by Di Zhang'''\n",
    "        sorted_names = []\n",
    "        S_no_parents = list(filter(lambda x: True if self.is_founder(x) else False, self.families[famid])) #change for py3 https://stackoverflow.com/questions/34820657/filter-object-has-no-attribute-pop\n",
    "        graph = self.graph[famid].copy()\n",
    "        while(S_no_parents):\n",
    "            n = S_no_parents.pop()\n",
    "            sorted_names.append(n)\n",
    "            if n not in graph:\n",
    "                continue\n",
    "            offsprings = graph.pop(n)\n",
    "            for m in offsprings:\n",
    "                father, mother = self.get_parents(m)\n",
    "                if father not in graph and mother not in graph:\n",
    "                    S_no_parents.append(m)\n",
    "        if graph:\n",
    "            raise ValueError(\"There is a loop in the pedigree: {}\\n\".format(' '.join(graph.keys())))\n",
    "        else:\n",
    "            return sorted_names\n",
    "\n",
    "    def __add_or_app(self, obj, key, value):\n",
    "        islist = type(value) is list\n",
    "        if key not in obj:\n",
    "            if not islist:\n",
    "                obj[key] = [value]\n",
    "            else:\n",
    "                obj[key] = value\n",
    "        else:\n",
    "            if value not in obj[key]:\n",
    "                if not islist:\n",
    "                    obj[key].append(value)\n",
    "                else:\n",
    "                    obj[key].extend(value)\n",
    "\n",
    "    def __update_graph(self, g, info):\n",
    "        if info[2] != \"0\" and info[3] != \"0\":\n",
    "            g[info[0]][info[2]].append(info[1])\n",
    "            g[info[0]][info[3]].append(info[1])\n",
    "\n",
    "    def __parse(self, tfam):\n",
    "        '''Rules:\n",
    "        1. samples have to have unique names\n",
    "        2. both parents for a non-founder should be available\n",
    "        3. founders should have at least one offspring'''\n",
    "        fams = OrderedDict()\n",
    "        samples = OrderedDict()\n",
    "        graph = defaultdict(lambda : defaultdict(list))\n",
    "        if tfam is None:\n",
    "            return fams, samples, graph\n",
    "        observedFounders = {}\n",
    "        expectedParents = {}\n",
    "        #\n",
    "        # Load TFAM file\n",
    "        #\n",
    "        with open(tfam, 'r') as f:\n",
    "            for idx, line in enumerate(f.readlines()):\n",
    "                line = line.split()\n",
    "                if len(line) != 6:\n",
    "                    env.error(\"skipped line {} (has {} != 6 columns!)\".format(idx, len(line)))\n",
    "                    continue\n",
    "                if line[1] in samples:\n",
    "                    env.error(\"skipped line {} (duplicate sample name '{}' found!)\".format(idx, line[1]))\n",
    "                    continue\n",
    "                # collect sample line\n",
    "                samples[line[1]] = [line[0], line[1], line[2], line[3], line[4], line[5]]\n",
    "                # collect family member\n",
    "                self.__add_or_app(fams, line[0], line[1])\n",
    "                # collect founders for family\n",
    "                if line[2] in env.ped_missing and line[3] in env.ped_missing:\n",
    "                    self.__add_or_app(observedFounders, line[0], line[1])\n",
    "                else:\n",
    "                    self.__add_or_app(expectedParents, line[0], (line[1], line[2], line[3]))\n",
    "        #\n",
    "        # Check sample parents\n",
    "        #\n",
    "        for k in expectedParents:\n",
    "            for person in expectedParents[k]:\n",
    "                if not (person[1] in fams[k] and person[2] in fams[k]):\n",
    "                    env.error(\"Cannot find parents ({} and {}) of {} in [{}]!\".\\\n",
    "                              format(person[1], person[2], person[0], tfam), exit = True)\n",
    "                    # missing both parents, make it a founder\n",
    "                    # samples[person[0]][2] = samples[person[0]][3] = \"0\"\n",
    "                    # observedFounders[k].append(person[0])\n",
    "                if person[1] in fams[k] and not person[2] in fams[k]:\n",
    "                    env.error(\"Cannot find mother ({}) of {} in [{}]!\".\\\n",
    "                              format(person[2], person[0], tfam), exit = True)\n",
    "                    # missing mother, mask as zero\n",
    "                    # samples[person[0]][3] = \"0\"\n",
    "                if not person[1] in fams[k] and person[2] in fams[k]:\n",
    "                    env.error(\"Cannot find father ({}) of {} in [{}]!\".\\\n",
    "                              format(person[1], person[0], tfam), exit = True)\n",
    "                    # missing father, mask as zero\n",
    "                    # samples[person[0]][2] = \"0\"\n",
    "        #\n",
    "        # Remove trivial families\n",
    "        #\n",
    "        for k in fams.keys():\n",
    "            if Counter(observedFounders[k]) == Counter(fams[k]):\n",
    "                del fams[k]\n",
    "                continue\n",
    "        #\n",
    "        valid_samples = []\n",
    "        for value in fams.values():\n",
    "            valid_samples.extend(value)\n",
    "        samples = {k : samples[k] for k in valid_samples}\n",
    "        #\n",
    "        for item in samples.values():\n",
    "            self.__update_graph(graph, item)\n",
    "        return fams, samples, graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def isnotebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, Process, Queue, Lock, Value, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
