{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main module\n",
    "\n",
    "> API details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from argparse import ArgumentParser, ArgumentTypeError, RawDescriptionHelpFormatter, SUPPRESS\n",
    "import os, glob, platform\n",
    "from multiprocessing import cpu_count, Queue\n",
    "from SEQLinkage.Utils import *\n",
    "from SEQLinkage.Runner import *\n",
    "from SEQLinkage.Core import *\n",
    "from multiprocessing import Process, Queue\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import sys, faulthandler, platform\n",
    "import numpy as np\n",
    "import os\n",
    "if sys.version_info.major == 2:\n",
    "    from cstatgen import cstatgen_py2 as cstatgen\n",
    "    from cstatgen.egglib import Align\n",
    "else:\n",
    "    from cstatgen import cstatgen_py3 as cstatgen\n",
    "    import egglib\n",
    "    from egglib import Align\n",
    "HOMEPAGE = 'http://bioinformatics.org/seqlink'  #fixme\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.parser = ArgumentParser(\n",
    "        description = '''\\t{}, linkage analysis using sequence data\\n\\t[{}]'''.\\\n",
    "        format(\"SEQLinkage\", VERSION),\n",
    "        formatter_class = RawDescriptionHelpFormatter,\n",
    "        prog = 'seqlink',\n",
    "        fromfile_prefix_chars = '@', add_help = False,\n",
    "        epilog = '''\\tCopyright (c) 2013 - 2014 Gao Wang <wang.gao@columbia.edu>\\n\\tDistributed under GNU General Public License\\n\\tHome page: {}'''.format(HOMEPAGE))\n",
    "        self.getEncoderArguments(self.parser)\n",
    "        self.getIOArguments(self.parser)\n",
    "        self.getLinkageArguments(self.parser)\n",
    "        self.getRuntimeArguments(self.parser)\n",
    "\n",
    "    def isalnum(self, string):\n",
    "        if not os.path.basename(string).isalnum():\n",
    "            raise ArgumentTypeError(\"Illegal path name [%]: must be alphanumerical string.\" % string)\n",
    "        return string\n",
    "\n",
    "    def get(self):\n",
    "        return self.parser.parse_args()\n",
    "\n",
    "    def getEncoderArguments(self, parser):\n",
    "        vargs = parser.add_argument_group('Collapsed haplotype pattern method arguments')\n",
    "        vargs.add_argument('--bin', metavar = \"FLOAT\", default = 0, type = float,\n",
    "                           help='''Defines theme to collapse variants. Set to 0 for \"complete collapsing\",\n",
    "        1 for \"no collapsing\", r2 value between 0 and 1 for \"LD based collapsing\" and other integer values for customized\n",
    "        collapsing bin sizes. Default to 0 (all variants will be collapsed).''')\n",
    "        vargs.add_argument('-b', '--blueprint', metavar = 'FILE',\n",
    "                           help='''Blueprint file that defines regional marker\n",
    "        (format: \"chr startpos endpos name avg.distance male.distance female.distance\").''')\n",
    "        vargs.add_argument('--chp-markers', action='store_true', dest = \"chp_markers\",\n",
    "                           help='''Use chp markers if True else single variants.''')\n",
    "\n",
    "    def getIOArguments(self, parser):\n",
    "        vargs = parser.add_argument_group('Input / output options')\n",
    "        vargs.add_argument('--fam', metavar='FILE', required=True, dest = \"tfam\",\n",
    "                           help='''Input pedigree and phenotype information in FAM format.''')\n",
    "        vargs.add_argument('--vcf', metavar='FILE', required=True, help='''Input VCF file, bgzipped.''')\n",
    "        vargs.add_argument('--anno', metavar='FILE', required=False, help='''Input annotation file from annovar.''')\n",
    "        vargs.add_argument('--pop', metavar='FILE', required=False, help='''Input two columns file, first column is family ID, second column population information.''')\n",
    "        vargs.add_argument('--included-vars', metavar='FILE', dest='included_vars',default=None, help='''Variants to be included for linkage analysis, if None, the analysis won't filter any variants. But you can still set AF cutoff by -c argment.''')\n",
    "        vargs.add_argument('-c', '--maf-cutoff', metavar='P', default=1.0, type=float, dest = \"maf_cutoff\",\n",
    "                           help='''MAF cutoff to define variants to be excluded from analyses. this is useful, if you need to analyse multiple population together.''')\n",
    "        \n",
    "        vargs.add_argument('--build', metavar='STRING', default='hg38', choices = [\"hg19\", \"hg38\"], help='''Reference genome version for VCF file.''')\n",
    "        vargs.add_argument('--freq', metavar='INFO', default = None,help='''Info field name for allele frequency in VCF file.''')\n",
    "        #vargs.add_argument('--freq_by_fam', metavar='INFO', help='''Per family info field name for allele frequency in VCF file.''')\n",
    "        #vargs.add_argument('--mle', action='store_true', help='''Estimate allele frequency using MERLIN's MLE method.''')\n",
    "        #vargs.add_argument('--rvhaplo', action='store_true', help='''Only using rare variants for haplotyping''')\n",
    "        #vargs.add_argument('--recomb_max', metavar='INT', default = 1, type = int, help='''Maximum recombination events allowed per region.''')\n",
    "        #vargs.add_argument('--recomb_cross_fam', action='store_true', help='''Code sub-regions with cross family recombination events; otherwise sub-regions are generated on per family basis.''')\n",
    "        #vargs.add_argument('--rsq', metavar='R', default=0.0,type=float, help=SUPPRESS)\n",
    "        \n",
    "        vargs.add_argument('--chrom-prefix', metavar='STRING', dest = 'chr_prefix',\n",
    "                           help='''Prefix to chromosome name in VCF file if applicable, e.g. \"chr\".''')\n",
    "        vargs.add_argument('-o', '--output', metavar='Name', type = self.isalnum,\n",
    "                           help='''Output name prefix.''')\n",
    "        vargs.add_argument('-f', '--format', metavar = 'FORMAT', nargs='+',\n",
    "                           choices = [\"LINKAGE\", \"MERLIN\", \"MEGA2\", \"PLINK\"], default=['LINKAGE'],\n",
    "                           help='''Output format. Default to LINKAGE.''')\n",
    "\n",
    "    def getRuntimeArguments(self, parser):\n",
    "        vargs = parser.add_argument_group('Runtime arguments')\n",
    "        vargs.add_argument(\"-h\", \"--help\", action=\"help\", help=\"Show help message and exit.\")\n",
    "        vargs.add_argument('-j', '--jobs', metavar='N', type = int, default = max(min(int(cpu_count() / 2), 8), 1),\n",
    "                           help='''Number of CPUs to use.''')\n",
    "        vargs.add_argument('--tempdir', metavar='PATH',\n",
    "                           help='''Temporary directory to use.''')\n",
    "        vargs.add_argument('--cache', action='store_false', dest = 'vanilla',\n",
    "                           help='''Load cache data for analysis instead of starting from scratch.''')\n",
    "        vargs.add_argument('-q', '--quiet', action='store_true', help='Disable the display of runtime MESSAGE.')\n",
    "        vargs.add_argument('--debug', action='store_true', help=SUPPRESS)\n",
    "        vargs.add_argument('--no-save', action='store_true', dest='no_save', help=SUPPRESS)\n",
    "\n",
    "    def getLinkageArguments(self, parser):\n",
    "        vargs = parser.add_argument_group('LINKAGE options')\n",
    "        vargs.add_argument('-K', '--prevalence', metavar='FLOAT', type=float,\n",
    "                           help='Disease prevalence.')\n",
    "        vargs.add_argument('--moi', metavar='STRING', dest = \"inherit_mode\",\n",
    "                           # choices=['AD', 'AR', 'Xlinked', 'Y'],\n",
    "                           choices=['AD', 'AR'],\n",
    "                           help='Mode of inheritance, AD/AR: autosomal dominant/recessive.')\n",
    "        vargs.add_argument('-W', '--wt-pen', metavar='FLOAT', type=float, dest = \"wild_pen\",\n",
    "                           help='Penetrance for wild type.')\n",
    "        vargs.add_argument('-M', '--mut-pen', metavar='FLOAT', type=float, dest = \"muta_pen\",\n",
    "                           help='Penetrance for mutation.')\n",
    "        vargs.add_argument('--theta-max', metavar='FLOAT', type=float, dest = \"theta_max\", default = 0.5,\n",
    "                           help='Theta upper bound. Default to 0.5.')\n",
    "        vargs.add_argument('--theta-inc', metavar='FLOAT', type=float, dest = \"theta_inc\", default = 0.05,\n",
    "                           help='Theta increment. Default to 0.05.')\n",
    "        if ((platform.system() == 'Linux' or platform.system() == 'Darwin') and platform.architecture()[0] == '64bit'):\n",
    "            vargs.add_argument('--run-linkage', action='store_true', dest = \"run_linkage\",\n",
    "                           help='''Perform Linkage analysis using FASTLINK program.''')\n",
    "            vargs.add_argument('--output-entries', metavar='N', type=int, dest = \"output_limit\", default = 10,\n",
    "                           help='Write the highest N LOD/HLOD scores to output tables. Default to 10.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def checkParams(args):\n",
    "    '''set default arguments or make warnings'''\n",
    "    env.setoutput(args.output)\n",
    "    env.debug = args.debug\n",
    "    env.quiet = args.quiet\n",
    "    args.vcf = os.path.abspath(os.path.expanduser(args.vcf))\n",
    "    args.tfam = os.path.abspath(os.path.expanduser(args.tfam))\n",
    "    for item in [args.vcf, args.tfam]:\n",
    "        if not os.path.exists(item):\n",
    "            env.error(\"Cannot find file [{}]!\".format(item), exit = True)\n",
    "    if len([x for x in set(getColumn(args.tfam, 6)) if x.lower() not in env.ped_missing]) > 2:\n",
    "        env.trait = 'quantitative'\n",
    "    env.log('{} trait detected in [{}]'.format(env.trait.capitalize(), args.tfam))\n",
    "    if not args.blueprint:\n",
    "        if not args.anno:\n",
    "            args.blueprint = os.path.join(env.resource_dir, 'genemap.{}.txt'.format(args.build))\n",
    "        else:\n",
    "            env.log('Generate regions by annotation')\n",
    "    args.format = [x.lower() for x in set(args.format)]\n",
    "    if args.run_linkage and \"linkage\" not in args.format:\n",
    "        args.format.append('linkage')\n",
    "    if None in [args.inherit_mode, args.prevalence, args.wild_pen, args.muta_pen] and \"linkage\" in args.format:\n",
    "        env.error('To generate LINKAGE format or run LINKAGE analysis, please specify all options below:\\n\\t--prevalence, -K\\n\\t--moi\\n\\t--wild-pen, -W\\n\\t--muta-pen, -M', show_help = True, exit = True)\n",
    "    if args.tempdir is not None:\n",
    "        env.ResetTempdir(args.tempdir)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def main():\n",
    "    '''the main encoder function'''\n",
    "    args = Args().get()\n",
    "    checkParams(args)\n",
    "    download_dir = 'http://bioinformatics.org/spower/download/.private'\n",
    "    downloadResources([('{}/genemap.{}.txt'.format(download_dir, args.build), env.resource_dir),\n",
    "                       ('{}/{}/mlink'.format(download_dir, platform.system().lower()), env.resource_bin),\n",
    "                       ('{}/{}/unknown'.format(download_dir, platform.system().lower()), env.resource_bin),\n",
    "                       ('{}/{}/makeped'.format(download_dir, platform.system().lower()), env.resource_bin),\n",
    "                       ('{}/{}/pedcheck'.format(download_dir, platform.system().lower()), env.resource_bin)])\n",
    "    if args.no_save:\n",
    "        cache = NoCache()\n",
    "    else:\n",
    "        cache = Cache(env.cache_dir, env.output, vars(args))\n",
    "    cache.setID('vcf')\n",
    "    # STEP 1: write encoded data to TPED format\n",
    "    if not args.vanilla and cache.check():\n",
    "        env.log('Loading regional marker data from archive ...')\n",
    "        cache.load(target_dir = env.tmp_dir, names = ['CACHE'])\n",
    "        env.success_counter.value = sum(map(fileLinesCount, glob.glob('{}/*.tped'.format(env.tmp_cache))))\n",
    "        env.batch = 10\n",
    "    else:\n",
    "        # load data\n",
    "        data = RData(args.vcf, args.tfam,args.anno,args.pop,allele_freq_info=args.freq,included_variant_file=args.included_vars)\n",
    "        samples_vcf = data.samples_vcf\n",
    "\n",
    "        if len(samples_vcf) == 0:\n",
    "            env.error(\"Fail to extract samples from [{}]\".format(args.vcf), exit = True)\n",
    "        env.log('{:,d} samples found in [{}]'.format(len(samples_vcf), args.vcf))\n",
    "        samples_not_vcf = data.samples_not_vcf\n",
    "\n",
    "        if len(data.families) == 0:\n",
    "            env.error('No valid family to process. ' \\\n",
    "                      'Families have to be at least trio with at least one member in VCF file.', exit = True)\n",
    "        if len(data.samples) == 0:\n",
    "            env.error('No valid sample to process. ' \\\n",
    "                      'Samples have to be in families, and present in both TFAM and VCF files.', exit = True)\n",
    "        rewriteFamfile(os.path.join(env.tmp_cache, '{}.tfam'.format(env.output)),\n",
    "                       data.tfam.samples, list(data.samples.keys()) + samples_not_vcf)\n",
    "      \n",
    "        if args.blueprint is not None:\n",
    "            # load blueprint\n",
    "            try:\n",
    "                env.log('Loading marker map from [{}] ...'.format(args.blueprint))\n",
    "                with open(args.blueprint, 'r') as f:\n",
    "                    regions = [x.strip().split() for x in f.readlines()]\n",
    "            except IOError:\n",
    "                env.error(\"Cannot load regional marker blueprint [{}]. \".format(args.blueprint), exit = True)\n",
    "        else:\n",
    "            env.log('separate chromosome to regions')\n",
    "            regions=data.get_regions(step=1000)\n",
    "        env.log('{:,d} families with a total of {:,d} samples will be scanned for {:,d} pre-defined units'.\\\n",
    "                format(len(data.families), len(data.samples), len(regions)))\n",
    "        env.jobs = max(min(args.jobs, len(regions)), 1)\n",
    "        env.log('Phasing haplotypes log file: [{}]'.format(env.tmp_log + str(os.getpid()) + '.log'))\n",
    "        try:\n",
    "            if env.jobs>1:\n",
    "                regions.extend([None] * env.jobs)\n",
    "                queue = Queue()\n",
    "                faulthandler.enable(file=open(env.tmp_log + '.SEGV', 'w'))\n",
    "                for i in regions:\n",
    "                    queue.put(i)\n",
    "                jobs = [EncoderWorker(\n",
    "                    queue, len(regions), data,\n",
    "                    RegionExtractor(args.vcf, build = args.build, chr_prefix = args.chr_prefix),\n",
    "                    MarkerMaker(args.bin, maf_cutoff = args.maf_cutoff),\n",
    "                    LinkageWriter(len(samples_not_vcf)),\n",
    "                    ) for i in range(env.jobs)]\n",
    "                for j in jobs:\n",
    "                    j.start()\n",
    "                for j in jobs:\n",
    "                    j.join()\n",
    "                faulthandler.disable()\n",
    "            else:\n",
    "                run_each_region(regions,data,RegionExtractor(args.vcf, build = args.build, chr_prefix = args.chr_prefix),\n",
    "                    MarkerMaker(args.bin, maf_cutoff = args.maf_cutoff),\n",
    "                    LinkageWriter(len(samples_not_vcf)),args.phase)\n",
    "        except KeyboardInterrupt:\n",
    "            # FIXME: need to properly close all jobs\n",
    "            raise ValueError(\"Use 'killall {}' to properly terminate all processes!\".format(env.prog))\n",
    "        else:\n",
    "            env.log('{:,d} units (from {:,d} variants) processed; '\\\n",
    "                '{:,d} Mendelian inconsistencies and {:,d} recombination events handled\\n'.\\\n",
    "                format(env.success_counter.value,\n",
    "                       env.variants_counter.value,\n",
    "                       env.mendelerror_counter.value,\n",
    "                       env.recomb_counter.value), flush = True)\n",
    "            if env.triallelic_counter.value:\n",
    "                env.log('{:,d} tri-allelic loci were ignored'.format(env.triallelic_counter.value))\n",
    "            if env.commonvar_counter.value:\n",
    "                env.log('{:,d} variants ignored due to having MAF > {}'.\\\n",
    "                        format(env.commonvar_counter.value, args.maf_cutoff))\n",
    "            if env.null_counter.value:\n",
    "                env.log('{:,d} units ignored due to absence in VCF file'.format(env.null_counter.value))\n",
    "            if env.trivial_counter.value:\n",
    "                env.log('{:,d} units ignored due to absence of variation in samples'.format(env.trivial_counter.value))\n",
    "            fatal_errors = 0\n",
    "            try:\n",
    "                # Error msg from C++ extension\n",
    "                os.system(\"cat {}/*.* > {}\".format(env.tmp_dir, env.tmp_log))\n",
    "                fatal_errors = wordCount(env.tmp_log)['fatal']\n",
    "            except KeyError:\n",
    "                pass\n",
    "            if env.chperror_counter.value:\n",
    "                env.error(\"{:,d} regional markers failed to be generated due to haplotyping failures!\".\\\n",
    "                          format(env.chperror_counter.value))\n",
    "            if fatal_errors:\n",
    "                env.error(\"{:,d} or more regional markers failed to be generated due to runtime errors!\".\\\n",
    "                          format(fatal_errors))\n",
    "            env.log('Archiving regional marker data to directory [{}]'.format(env.cache_dir))\n",
    "            cache.write(arcroot = 'CACHE', source_dir = env.tmp_cache)\n",
    "    env.jobs = args.jobs\n",
    "    # STEP 2: write to PLINK or mega2 format\n",
    "    tpeds = [os.path.join(env.tmp_cache, item) for item in os.listdir(env.tmp_cache) if item.startswith(env.output) and item.endswith('.tped')]\n",
    "    for fmt in args.format:\n",
    "        cache.setID(fmt.lower())\n",
    "        if not args.vanilla and cache.check(path=os.path.join(env.outdir,fmt.upper())):\n",
    "            env.log('Loading {} data from archive ...'.format(fmt.upper()))\n",
    "            cache.load(target_dir = env.tmp_dir, names = [fmt.upper()])\n",
    "        else:\n",
    "            env.log('{:,d} units will be converted to {} format'.format(env.success_counter.value, fmt.upper()))\n",
    "            env.format_counter.value = 0\n",
    "            format(tpeds, os.path.join(env.tmp_cache, \"{}.tfam\".format(env.output)),\n",
    "                   args.prevalence, args.wild_pen, args.muta_pen, fmt,\n",
    "                   args.inherit_mode, args.theta_max, args.theta_inc)\n",
    "            env.log('{:,d} units successfully converted to {} format\\n'.format(env.format_counter.value, fmt.upper()), flush = True)\n",
    "            if env.skipped_counter.value:\n",
    "                # FIXME: perhaps we need to rephrase this message?\n",
    "                env.log('{} region - family pairs skipped'.format(env.skipped_counter.value))\n",
    "            env.log('Archiving {} format to directory [{}]'.format(fmt.upper(), env.cache_dir))\n",
    "            cache.write(arcroot = fmt.upper(),\n",
    "                        source_dir = os.path.join(env.tmp_dir, fmt.upper()), mode = 'a')\n",
    "\n",
    "    if args.run_linkage:\n",
    "        cache.setID('analysis')\n",
    "        if not args.vanilla and cache.check(path=os.path.join(env.outdir,'heatmap')):\n",
    "            env.log('Loading linkage analysis result from archive ...'.format(fmt.upper()))\n",
    "            cache.load(target_dir = env.outdir, names = ['heatmap'])\n",
    "        else:\n",
    "            env.log('Running linkage analysis ...'.format(fmt.upper()))\n",
    "            run_linkage(args.blueprint, args.theta_inc, args.theta_max, args.output_limit)\n",
    "            env.log('Linkage analysis succesfully performed for {:,d} units\\n'.\\\n",
    "                    format(env.run_counter.value, fmt.upper()), flush = True)\n",
    "            if env.makeped_counter.value:\n",
    "                env.log('{} \"makeped\" runtime errors occurred'.format(env.makeped_counter.value))\n",
    "            if env.pedcheck_counter.value:\n",
    "                env.log('{} \"pedcheck\" runtime errors occurred'.format(env.pedcheck_counter.value))\n",
    "            if env.unknown_counter.value:\n",
    "                env.log('{} \"unknown\" runtime errors occurred'.format(env.unknown_counter.value))\n",
    "            if env.mlink_counter.value:\n",
    "                env.log('{} \"mlink\" runtime errors occurred'.format(env.mlink_counter.value))\n",
    "            cache.write(arcroot = 'heatmap', source_dir = os.path.join(env.outdir, 'heatmap'), mode = 'a')\n",
    "        html(args.theta_inc, args.theta_max, args.output_limit)\n",
    "    else:\n",
    "        env.log('Saving data to [{}]'.format(os.path.abspath(env.outdir)))\n",
    "        cache.load(target_dir = env.outdir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
